META :
	ces notes sont pseudo-archiv√©es ici, m√™me si elles n'ont pas √©t√© clean√©es
	l'id√©e est de d√©charger mes journaux dans lesquels elles √©taient stock√©es + de les rendre publiquement accessibles sans attendre
	(un jour peut-√™tre je ferai le m√©nage : il y a PLEIN de trucs int√©ressants l√†-dedans !)

NOTES VRAC :
	NOTES VRAC SUR LE ROUTING
		Ressources qui ont l'air bien :
			https://jlazarsfeld.github.io/ch.150.project/contents/
			https://rahvee.gitlab.io/comparison-nearest-neighbor-search/
			https://www.eecs.tufts.edu/~aloupis/comp150/projects-summer18.html
		https://www3.cs.stonybrook.edu/~rezaul/papers/TR-07-54.pdf
			article de 2007 = impact des priority queues sur Dijkstra
		https://www.redblobgames.com/pathfinding/a-star/introduction.html
			Les animations sont super : quels outils ont √©t√© utilis√©s ?! Il y a des √©l√©ments de r√©ponse dans les commentaires
			Cette autre page explique comment il fait des tutos interactifs : https://www.redblobgames.com/making-of/line-drawing/
			Grosso modo, tout le blog est super !!!
		Pourquoi est-ce que Dijkstra ne trouve pas le Minimum Spanning Tree :
			https://stackoverflow.com/a/20482220
		Lien sur le multimodal Valhalla :
			https://valhalla.readthedocs.io/en/latest/route_overview/
		NOTES WCH
			WCH - r√©flexion sur la customization, en repartant de la th√®se :
				√† l'issue du preprocess, on a un graphe original + des shortcuts ajout√©s par le preprocess (witnessless, donc exhaustif)
				la m√©trique originale lenG associe un cost √† tout edge original (et tous les autres costs sont suppos√©s √™tre +‚àû)
				l'algorithme 4.1 de customization "contracte" chaque node V dans l'ordre d'ordering
				exemple pour m'aider √† comprendre :
					notation : U est un pr√©d√©cesseur de V, W est un successeur de V
					pour le premier node V contract√© (celui qui a le rank le moins √©lev√©), on it√®re sur ses paires (U,W)
					on regarde si le poids de l'edge UW est sup√©rieur √† la somme des poids UV + VW
					ici, UW est un shortcut (on laisse de c√¥t√© le cas o√π un edge similaire existe pour le moment) donc il a un poids infini +‚àû
					UV et VW sont des edges r√©els, ils ont un poids fini dans la m√©trique lenG
					CONCLUSION : on attribue √† UW le poids somme, et on sette V comme middle-node de UW
				mes questions :
					question 1 = quid si l'edge existait d√©j√† ?
					question 2 = quid si l'un des demi-edge (ou les deux) est un shortcut ?
					question 3 = pourquoi ne peut-on pas simplement dire que le poids du shortcut est la somme des poids des deux demi-edges ?
				question 1 = quid si l'edge existait d√©j√† ?
					si on n'a pas am√©lior√© son poids, on le laisse intact (avec le poids qu'on n'a pas am√©lior√©, et le middle-node qu'il utilisait)
					si on a am√©lior√© son poids, on mets √† jour son poids et son middle-node
					in fine, √ßa ne change pas grand-chose
				question 2 = quid si l'un des demi-edge (ou les deux) est un shortcut ?
					le seul point qui peut √™tre g√™nant, c'est que ces demi-edges peuvent du coup ne PAS avoir encore de m√©trique (car √† la base, seuls les edges originaux ont une m√©trique, les shortcuts sont √† +‚àû)
					j'ai pris une note sur le sujet plus haut, mais grosso-modo, le fait de customizer le graphe dans l'ordre donn√© par l'ordering GARANTIT que m√™me si les demi-edges sont des shortcuts, ils ont d√©j√† une m√©trique
				question 3 = pourquoi ne peut-on pas simplement dire que le poids du shortcut est la somme des poids des deux demi-edges ?
					car si le shortcut UW existe d√©j√† (soit qu'il existe √©galement un arc original UW, soit qu'un autre shortcut UW a d√©j√† √©t√© cr√©√© pr√©c√©demment), il faut prendre le meilleur poids des deux !
					(sans quoi on risque d'√©craser le poids pr√©c√©dent avec un poids moins bon)
				----------------------------------------
				au passage, je comprends j'ai entendu "on recontracte tout le graphe √† chaque customization..."
				(en revanche, pour la prise en compte des voies ferm√©es dans le POC, on devrait pouvoir utiliser des mises √† jour incr√©mentales)
				----------------------------------------
				bon, √† l'issue de cette journ√©e d'analyse, m√™me s'il me reste beaucoup d'ordre √† donner √† mes notes, je pense avoir quasi tout compris √† l'impl√©mentation de WCH :-)
					notamment, j'ai bien compris √† quoi sert la construction d'un index des shortcuts (TL;DR : √† retrouver facilement un shortcut √† partir du couple {source,target})
						en d'autres termes, √ßa sert uniquement √† pouvoir √©crire √ßa :
							int shortcut_id = shortcut_indices[index];
							shortcut_id += successors.get_node_first_edge_id(source_node);
							QuerySuccessor& shortcut = successors.get_mut_value(shortcut_id);
						plut√¥t que quelque chose dans le genre de √ßa :
							int shortcut_id = successors.find_first(source_id, target_id)  // Tr√®s long, car u
							QuerySuccessor& shortcut = successors.get_mut_value(
						En effet, l'impl√©mentation de find_first utilise une co√ªteuse boucle for :
							TAdjSize find_first(TNodeId from, TNodeId to) const {
								TAdjSize end = first_edge_ids[from + 1];
								for (TAdjSize i=first_edge_ids[from]; i < end; ++i) {
									if (target_nodes[i] == to) return i;
								}
							}
						en gros, √ßa ne sert qu'√† cette ligne, qui permet d'√©viter la boucle for...
					le seul truc qui m'intrigue, c'est que si j'ai bien suivi, on garde TOUS les shortcuts exhaustifs dans le graphe qui sert au query-time
					(alors que je me serais attendu √† ce que qu'on d√©gage les shortcuts inutiles)
					Dit autrement, on semble conserver dans le graphe beaucoup de shortcuts inutiles, car ils ne contribuent pas √† un plus court chemin
					√Ä v√©rifier dynamiquement avec un bout de code √©tudiant un graphe WCH ?
						EDIT = j'ai test√©, et j'ai confirm√©, en utilisant le graphe de ma POC 10 de GLIFOV :
							un node N a 3 pr√©d√©cesseurs (A, B, C) et deux successeurs (X et Y), et le graphe a deux noeuds suppl√©mentaires NORTH et SOUTH
							il y a donc 6 shortcuts possibles, et le graphe est construit pour que la contraction de N ne n√©cessite que 4 shortcuts
							(les autres shortcuts ne sont pas n√©cessaires car on peut trouver des witness-path passant par SOUTH)
							en chargeant ce graphe simpliste dans un graphe CH, la contraction ne g√©n√®re bien que les 4 shortcuts
							en chargeant ce graphe simpliste dans un graphe WCH, la contraction g√©n√®re 6 shortcuts !
							√ßa confirme donc ce que je pensais = dans le graphe WCH, on ajoute TOUS les shortcuts, peu importe qu'ils soient n√©cessaires ou non
							(et du coup, toutes choses √©tant √©gales par ailleurs, une requ√™te WCH sera plus lente qu'une requ√™te CH, m√™me si le graphe est identique)
			Notes tr√®s vrac sur la customization (section 4) :
				NdM :
					√† ce stade, on a fait une premi√®re √©tape de preprocessing sans m√©trique :
						pour chaque node (dans l'ordre donn√©e par l'ordering), on a ajout√© tous les shortcuts possibles
						le graphe dont on dispose est donc le graphe original, augment√© de tous les shortcuts
					la customization consiste √† attribuer un poids √† tous les tron√ßons :
						les tron√ßons originaux
						les shortcuts exhaustifs ajout√©s par le preprocessing
					la donn√©e d'entr√©e de la customization :
						le graphe pr√©process√© (tron√ßons originaux + shortcuts)
						une m√©trique = le poids de chaque tron√ßon original
					na√Øvement, on pourrait :
						1. it√©rer sur chaque tron√ßon original pour leur attribuer le poids
						2. it√©rer sur chaque raccourci pour (r√©cursivement si n√©cessaire) attribuer le poids du raccourci comme la somme des poids des demi-edges
				Paragraphe d'intro :
					il semble y avoir une autre optique qui est d'introduire de PETITS changements sur un graphe qui dispose d√©j√† d'une m√©trique d√©finie (donc d√©j√† customis√©)
						l'id√©e sera d'identifier les nodes concern√©s par le petit changement de m√©trique (p.ex. l'augmentation du poids d'UN tron√ßon)
						il "suffit" alors de refaire la contraction de ces nodes uniquement
					la section 4 est divis√©e en deux parties :
						1 = application d'une m√©trique sur un graphe sans m√©trique
						2 = introduction d'une petite modification sur une m√©trique existante
					la performance de la customization est importante, car √† la diff√©rence du preprocess CH (qui est fait une seule fois, en offline), la customization sera lanc√©e tr√®s souvent
				Section 4.1 = basic approach
					premier paragraphe = le couple WCH {witnessless preprocess + customization} devrait in fine conduire au m√™me r√©sultat qu'un preprocess CH classique
					inputs :
						graphe original
						weak contraction (= le graphe original + les shortcuts exhaustifs)
						ordering Œ±
						m√©trique LEN
					steps :
						1 = calculer le poids des shortcuts
						2 = mettre √† jour (pour les raccourcir si besoin) le poids des arcs originaux concern√©s (les arcs originaux AB pour lesquel le plus court chemin est diff√©rent (par exemple AXYB), dont il existe un shortcut AB)
						3 = r√©cup√©rer le middle-node (que la th√®se appelle le "supporting node") de chaque shortcut (ou des arcs originaux dont le poids a √©t√© diminu√©r √† cause d'un shortcut). Si l'edge est original et non diminu√©, le middle-node est nul.
					l'algorithme 4.1 donne le principe de base de la customization :
						it√©rer sur tous les nodes v dans l'ordre donn√© par l'ordering Œ±
						it√©rer sur tous les shortcuts passant par v (i.e. tous les couples {pr√©d√©cesseur,successeur} de v) (NdM : vu que le preprocess les a cr√©√©s exhaustivement, ils sont tous l√† normalement)
						si le cost du shortcut (qui √©tait initialis√©e √† l'infini, sauf pour les edges originaux) est sup√©rieure √† la somme des deux demi-edges, alors on update le cost du shortcut, et on marque v comme middle-node du shortcut
					je ne prends pas de notes sur les microinstructions vu qu'elles ne sont pas utilis√©es au final
					macro-instructions :
						pour chaque node, on s'int√©resse aux paires d'arcs {input, output} (chaque paire d'arc correspond √† un shortcut exhaustif)
						on stocke alors pour chaque paire d'arc le shortcut correspondant
						cette fa√ßon de faire nous permet de retrouver facilement les shortcuts d'un node donn√©
						du coup lorsqu'on cherche √† mettre √† jour les poids des arcs incidents √† un node donn√©, il nous suffit alors d'it√©rer sur ses shortcuts par ce moyen
						lorsque le poids des shortcuts est d√©fini/am√©lior√© via ce node, on peut alors utiliser ce node comme middle-node
					NdM : fort de tout √ßa, √† quoi je m'attends du c√¥t√© de l'impl√©mentation WCH :
						phase de preprocessing = on ajoute au graphe tous les shortcuts d'un node donn√© exhaustivement
						phase de preprocessing = on remplit une structure permettant de retrouver tous les shortcuts d'un node donn√© (i.e. toutes les paires {in-edge,out-edge})
						phase de customization = on it√®re sur tous les noeuds, dans l'ordre de l'ordering
							on it√®re sur tous les shortcuts exhaustif du noeud
							pour chacun des shortcuts, si son poids est sup√©rieur √† la somme des poids des deux demi-edges, ont met √† jour le poids du shortcut, et on sette son middle-node)
							(note : "shortcut" au sens large, l'edge peut √©galement √™tre un edge original, s'il existe deux chemins pour faire AB : un edge direct AB, et deux edges AXB)
							(note : comme on it√®re dans l'ordre de l'ordering, pour le node courant, on est s√ªr que m√™me si certains de ses in-edges/out-edges sont des shortcuts, ils se sont d√©j√† vus attribuer un poids par une it√©ration pr√©c√©dente)
					NdM : √† ce stade, √† l'issue de la customization, tous les edges (notamment : tous les shortcuts exhaustifs) du graphe se sont vus attribuer un poids. Mais on a tout de m√™me beaucoup trop d'edge par rapport √† une CH classique ?!
				Section 4.2 = Incremental Metric Updates :
					NdM : a priori pas utilis√©, car on sette le poids de tous les tron√ßons (en utilisant l'information histo) au d√©but de chaque customization ?
			Notes th√®se WCH :
				https://i11www.iti.kit.edu/_media/teaching/theses/weak_ch_work-1.pdf
				Notes en cours :
					SECTION 2 PRELIMINARIES
						Terminologie : Node discover
						K-heap = plus efficace que heap (et fiboheap) pour dijkstra
					SECTION 3 CONTRACTION HI√âRARCHIES
						minimal contraction hi√©rarchie (pour un orderering donn√©) = la CH o√π on n'a ajout√© QUE les shortcuts n√©cessaires. Dit autrement, on a men√© chaque local search jusqu'√† son terme.
						Comme ils ne contiennent que des edges qui montent les ranks, les graphes upward et downward sont acycliques
						3.2 = sp√©cificit√© wch = witnessless node contraction
						3.3 d√©finition formelle d'une ch, et d'une weak ch
						En gros, une wch, c'est une ch avec de possibles shortcuts en trop
						Une maximal wch, c'est une wch avec tous les shortcuts possibles en trop. On l'obtient d'ailleurs suite √† une witnessless contraction.
						Tr√®s fort lien de la maximal wch avec l'√©limination game. En effet, l'√©limination game correspond √† la witnessless contraction, sur un graphe undirected, selon un certain ordre. Du coup, √† l'issue de celle-ci, une fois que le n≈ìud contract√© a √©t√© supprim√©, ses voisins forment une clique (vu qu'on les a tous reli√©s par des shortcuts).
						Le r√©sultat d'une Max-wch (et de √©limination game) est un graphe chordal.
						√âlimination tree (flemme de prendre des notes, mais il est d√©crit apr√®s la d√©finition 3.6, page 11).
						Th√©or√®me 3.8 : le search Space Size d'une wch est born√© par le search Space Size dans l'elimination tree. (Je saute la preuve par r√©currence, mais elle a l'air √† peu pr√®s compr√©hensible).
						Ce r√©sultat est important, car on dispose d√©j√† d'heuristiques permettant de trouver un ordering limitant la hauteur de l'√©limination tree !
						L'une d'entre elles est... La nested dissection üòâ
						Section 3.4 = nested dissection order
						Nested dissection = application r√©cursive d'un node separator.
						Nested dissection order = "ordering guid√© par la nested dissection" = on ranke les nodes de S plus haut que ceux de R et L.
						(Au sein de S, ou au sein de L ou R, on est libre de ranker comme on veut ; mais si R est lui m√™me subdivis√© en RS, RR, RL, alors les nodes de RS devront eux aussi √™tre rank√©s plus haut que ceux de RR et RL)
						Section 3.5 = lien entre ndorder et ch
						Application √† des gridgraphs dont chaque dimension est une puissance de deux moins un.
						Les exemples sont donn√©s sur un gridgraph 2^3-1 , 2^2-1 (soit : 7,3).
						Sur cet exemple, le s√©parateur coupe le graphe en deux le long de la plus petite dimension.
						Tr√®s tr√®s int√©ressante illustration du process (√† noter que l'ordering issu d'une nested dissection est partiellement arbitraire ce qui explique qu'on contracte d'abord toute la partie droite alors qu'il reste des nodes blancs √† gauche, cf. le dernier paragraphe juste avant la section 3.5)
						In fine, l'objectif de cette section 3.5 est de comprendre avec les mains la cons√©quence d'un ndorder sur la contraction ch. Il y a pas mal de conclusions utiles, qu'il faudra que j'annote proprement.
						Si je r√©sume, pour le moment, j'ai une id√©e assez claire de comment ordonner + contracter.
					SECTION 4 = CUSTOMIZATION
						√Ä partir d'une ch, appliquer de petits changements de poids d'edges. L'id√©e ma√Ætresse est d'identifier facilement les nodes impact√©s, et de ne recontracter QUE ces nodes.
						Point important = la customisation va √™tre faite souvent, elle doit √™tre RAPIDE.
						J'arr√™te l√† les notes, mais je continue la lecture.
				REPRENDRE LES NOTES √Ä :
					4.1 basic approach.
				REPRENDRE LA LECTURE √Ä :
					4.2 incremental metric updates
				Autres notes li√©es aux customizable contraction hierarchies = les algos de partitionning (et la rapide pr√©sentation des CCH/WCH dans leur article) :
					FlowCutter :
						https://arxiv.org/abs/1504.03812
						https://arxiv.org/pdf/1504.03812.pdf
						des papiers qui semblent int√©ressants - issus du papier sur FlowCutter (algo partitionnant les graphes) :
							Un papier qui semble int√©ressant : [graph partitioning with natural cuts](https://www.microsoft.com/en-us/research/wp-content/uploads/2010/12/punchTR.pdf) en 2010
							Un algo de partitioning encore plus r√©cent (qui s'appuie sur FlowCutter) = https://drops.dagstuhl.de/opus/volltexte/2019/11173/
							Un algo de partitioning sp√©cifiquement adapt√© √† CCH : https://arxiv.org/abs/1906.11811
						le papier pr√©sentant FlowCutter apporte plusieurs "overviews" int√©ressants :
							La section 3.3 du papier sur FlowCutter donne un excellent overview de CCH.
							Le papier donne √©galement une Overview du lien entre le partitioning et l'ordering.
							La section 3.4 donne un r√©sum√© de la th√©orie des tree decompositions, et donne des liens vers des surveys
							La fin de la section 3.5 donne un rapide overview des nested dissection.
							Si un jour j'ai le temps de m'int√©resser aux maths derri√®re le partitionnement du graphe (qui font que WCH marche bien), la section 3 de ce papier sera pr√©cieuse.
					FlowCutter + InertialFlow = InertialFlowCutter
						Faster and Better Nested Dissection Orders for Customizable Contraction Hierarchies
						https://arxiv.org/abs/1906.11811
						https://arxiv.org/pdf/1906.11811.pdf
						https://github.com/kit-algo/InertialFlowCutter
		ONBOARDING> NOTES VRAC ROUTING √Ä METTRE QQPART :
			Autres notes vrac :
				Du point de vue des PCC, quand on est sur un niveau de la hi√©rarchie, on a acc√®s (gr√¢ce aux raccourcis) √† un graphe r√©duit, mais sur lequel tous les pcc sont pr√©serv√©s !
				Note : on peut toujours forger un graphe sur lequel ch marchera mal, d'o√π 1 la difficult√© √† donner une complexit√© asymptotique garantie, et 2 la d√©pendance de celle-ci √† des param√®tres d√©pendants de la topologie du graphe (highway dimension et treewidth), car les graphes routiers v√©rifient tous certaines contraintes vis √† vis de ces param√®tres.
				Questions int√©ressantes issues de ce papier :
					Highway Dimension, Shortest Paths, and Provably Efficient Algorithms
					Can one prove sublinear query bounds for these heuristics on a non-trivial class of networks? For what graphs does the preprocessing/query framework lead to algorithms with provably good performance? Specifically, what properties of road networks imply provably good performance for the (de facto excellent) heuristics above? Finally, is there a plausible explanation as to why real road networks actually satisfy such conditions?
				Notion issue du m√™me papier : highway dimension caract√©rise la tendance des shortest paths √† se concentrer dans certains nodes. (Et ce serait pour √ßa que les graphes routiers ont une highway dimension faible : car cette caract√©ristique vient naturellement quand on essaye de cr√©er un r√©seau routier efficace. Par exemple, les transit nodes du r√©seau usa ne sont que 10000)
				Our motivation for the definition of highway dimension were the experiments performed by Bast et al. [1, 2], who exploited a very intuitive observation: when driving on a shortest path from a compact region of a road network to points that are ‚Äúfar away,‚Äù one must pass through one of a very small number of access nodes.
			Notes sur le papier CCH (en cours de lecture) :
				Ci dessous, les notes sur le papier CCH
				Section 1
				Apparemment, les queries cch sont plus rapides que les queries ch ! Dit autrement, l'ordering metric-independent est meilleur que metric-dependent ?!
				(Du coup, tester l'ordering cch pour le preprocess tch ?)
				Int√©ressant : pour un orderering donn√©, cch sait contracter avec un nombre optimal (ie minimal) de shortcut. Dit autrement, il n'y a pas d'approximation dans la recherche de witness-path
				Apparemment, les graphes routiers pr√©sentent la structure de s√©paration r√©cursive requise pour que un orderering bas√© sur les nested dissection conduise √† un search Space int√©ressant
				Le facteur qu'ils retiennent pour consid√©rer un s√©parateur balanced est 2/3 = 0.66
				D√©tail int√©ressant : un graphe upward est n√©cessairement acyclique (c'est un arbre, quoi)
			Un article int√©ressant sur ALT (dans GraphHopper) :
				https://www.graphhopper.com/blog/2017/08/14/flexible-routing-15-times-faster/
		AGR√âG√â DES NOTES DE PR√âPARATION DE LA PR√âSENTATION sur les CH :
			AUTRE = am√©lioration de ma connaissance des CH :
				pour ma culture = plotter les noeuds les plus importants d'une CH ? (je m'attends √† ce que ce soit des noeuds CENTRAUX, i.e. sur beaucoup de plus courts chemins)
					question = pourquoi l'ordering les classe en dernier ?
					ma r√©ponse = normalement, parce qu'ils vont g√©n√©rer un shortcut pour CHAQUE paire de leurs noeuds incidents (du coup, leur edge-difference sera tr√®s mauvaise)
				lorsque les deux propagation (ou une seule en fait) atteignent un certain niveau dans la hi√©rarchie, seul une sous-partie du graphe leurs sont accessibles.
					en l'occurence la sous-partie du graphe avec les nodes sup√©rieurs au niveau de hi√©rarchie o√π on est
				D'o√π la notion de "rejoindre" des niveaux √©lev√© dans la hi√©rarchie (qui se comprend mieux √† partir de Highway Hierarchies)
				On passe de ~2100 noeuds settled en unidir √† ~1500 en bidir (-600 = divis√© par 1.4 au lieu de 2) -> j'attribue √ßa au fait que vu le graphe, les cercles ne sont pas ronds.
					(on a donc moins √† √©conomiser)
				Un autre truc int√©ressant : si un noeud a tendance √† concentrer beaucoup de plus court chemin (c'est le cas √† monaco), il a int√©r√™t √† √™tre en haut de la hi√©rarchie
					s'il est en bas, le contracter t√¥t va g√©n√©rer beaucoup de shortcuts
				Encore un truc int√©ressant : depuis un noeud donn√©, on monte dans la hi√©rarchie par bonds (plut√¥t que cons√©cutivement) :
					par exemple, si le dijkstra forward commence au noeud de rank 1200, et qu'il a 4 out-edges (vers 1418, 2200, 1850 et 1870)
					√† la prochaine it√©ration, on sera d√©j√† au noeud de rank 1418 : on aura fait un bond de 218 dans la hi√©rarchie
					et le raisonnement sera le m√™me pour tous les noeuds : les out-edges des noeuds n'ont que peu de chances d'√™tre de rank cons√©cutifs -> on fait forc√©ment des "bonds" dans la hi√©rarchie
				l'id√©e ma√Ætresse c'est qu'en sautant 200 ranks, c'est AUTANT de nodes qu'on fait dispara√Ætre du graphe !
					c'est la troisi√®me et principale raison qui fait que CH va plus vite
					(avec le fait qu'on n'ajoute pas de shortcuts pour les edges qui ne sont pas des PCC, et le fait qu'on ajoute des shortcuts pour aller uniquement vers des edges de rank sup√©rieur)
					(les noeuds 1014 et 1015 de la pr√©sentation sont de bons exemples de √ßa)
				Ce qu'il faudra que j'aie fait pour la pr√©sentation :
					lecture de la th√®se
					lecture du papier ?
				T√ÇCHE DE REPRISE 1 = documenter dans mes notes github le code de la contraction et les structures ContractionHierarchy (cf. mes POCs)
					Explication rapidos (√† mieux formuler, et p√©renniser avec des liens vers le code) de la contraction :
						au moment de contracter un node, par d√©finition, il ne reste plus dans le graphe QUE des nodes d'ordre sup√©rieur
						on peut donc ajouter ses out-nodes comme successeurs dans la CH (ce qui est fait)
						une fa√ßon de voir les choses, c'est que la notion "d'ordre sup√©rieur" ne concerne QUE les voisins imm√©diats d'un node
						du coup, il serait TR√àS int√©ressant de calculer et afficher le graphe upward (ou downward)
					concernant les structures ch.forward  et  ch.backward, je les ai analys√©es en profondeur dans mes POCs sur RoutingKit, notamment ma POC5
				Ce qui serait top, ce serait de pouvoir visualiser la profondeur d'un BFS qui part d'un level donn√© :
					EDIT : TL;DR = c'est stupide comme id√©e, car le graphe √©tant connexe, il visitera tous les nodes
					sur mon graphe original, undirected, √† 2259 noeuds, tous les noeuds sont reli√©s (le graphe est connexe)
					lorsque je contracte un noeud et que je le supprime du graphe, je rajoute des edges pour pr√©server les shortest path !
					quoi qu'il arrive, √† chaque √©tape de la contraction, la connexit√© du graphe avec TOUS les noeuds restants est conserv√©e
					du coup, le cardinal (en nombre de noeuds) d'un BFS (ou d'un search-space sur un graphe en cours de contraction) sera √©gale au nombre de noeuds total sur le graphe !
			AUTRE = inclassable :
				Ce tuto a l'air pas mal pour un projet minimaliste python installable :
					https://packaging-guide.openastronomy.org/en/latest/minimal.html
				TODO RoutingKit : je pense qu'il y a un bug dans l'impl√©mentation, je peux soumettre un correctif :
					https://github.com/RoutingKit/RoutingKit/blob/fb5e83bcd4cf85763fb6877a0b5f8d5736c9a15b/src/contraction_hierarchy.cpp#L1028
					CODE ACTUEL :
						ch.backward.shortcut_second_arc[xy] = head[a];
					CODE CORRIG√â :
						ch.backward.shortcut_second_arc[xy] = tail[a];
					C'est pour √™tre coh√©rent avec ce commentaire, qui (actuellement) n'est vrai que si le demi-edge est le PREMIER :
						https://github.com/RoutingKit/RoutingKit/blob/fb5e83bcd4cf85763fb6877a0b5f8d5736c9a15b/include/routingkit/contraction_hierarchy.h#L60
						std::vector<unsigned>shortcut_second_arc;// contains input tail node ID if not shortcut
					√Ä faire avant de soumettre la review :
						confirmer : sans doute que √ßa ne pose pas souci dans l'unpacking, car celui-ci utilise le first-edge pour unpacker les r√©sultats ?
						√©crire un code montrant le probl√®me (comme ma POC)
				RoutingKit : essayer de reproduire le bug en for√ßant l'ordering sur un graphe simple ?
					du coup, s'il y a un bug √† l'unpacking, je pourrai peut-√™tre contribuer
			√Ä tester / v√©rifier :
				le fait que `estimate_node_importance` est la plus consommatrice de temps de contraction
				on dirait qu'on peut contracter en respectant un ordering particulier -> √ßa pourra m'√™tre utile pour mes tests :
					https://github.com/phidra/RoutingKit/blob/a0776b234ac6e86d4255952ef60a6a9bf8d88f02/src/contraction_hierarchy.cpp#L754
					void build_ch_given_rank(
						Graph&graph,
						ContractionHierarchy&ch,
						ContractionHierarchyExtraInfo&ch_extra,
						const std::vector<unsigned>&rank,
						unsigned max_pop_count,
						const std::function<void(std::string)>&log_message
					)
				essayer de contracter en ordre inverse et v√©rifier que √ßa fait exploser √† la fois le nombre d'edge et la profondeur du search-space d'un node donn√© (en moyenne)
				essayer de visualiser l'ordering des nodes d'un graphe simple pour comprendre comment c'est ordonn√©
				essayer de contracter le graphe de Monaco avec des orderings modifi√©s :
					score non-modifi√© (qui sert de r√©f√©rence)
					avec et sans chacun des trois crit√®res pour voir son impact
					avec uniquement l'un des trois crit√®res
					en random
					en order "anti-optimal"
					----------------------------------------
					il me faut de quoi visualiser/comprendre les cons√©quences de l'ordering :
						taille des search-space
						visualiser sur une carte les N nodes les plus (resp. moins) importants
						(√©ventuellement, visualiser le score d'ordering de chaque crit√®re pour chaque node, √† chaque √©tape de contraction ? Attention que √ßa fait N¬≤ scores √† m√©moriser)
						mesurer l'√©cart de rank moyen entre un node et ses successeurs dans le graphe ch.forward ?
					NOTE : ce que je cherche √† faire, c'est :
						1. faire une hypoth√®se sur ce que la modification d'un crti√®re va avoir comme impact (e.g. "si j'ignore le crit√®re sur les hops, je m'attends √† des contractions un peu moins r√©parties)
						2. trouver une m√©trique pour v√©rifier mon hypoth√®se (e.g. l'√©cart moyen de rank entre un node et ses successeurs dans le propagation-graph ch.forward devrait DIMINUER + la taille des search-space devrait augmenter)
						3. calculer la m√©trique pour v√©rifier mon hypoth√®se
				illustrer le besoin de r√©partition de contraction des nodes (avec la dead-end valley)
				faire des essais sur ordering / contraction pour mieux comprendre :
					il se passe quoi si on utilise un mauvais ordering ? (augmentation de la taille du search space size dans ce cas ?)
					combien d'edges r√©els survivent ?
					combien de shortcuts sont cr√©√©s ? (de quelle taille ?)
					mesurer la taille exhaustive du search-space depuis un node quelconque dans le propagation-graph (puis, de TOUS les nodes : c'est une m√©trique de la qualit√© de l'ordering)
					faire √ßa en C++ avec un binding python ?
			ce qui n'est pas encore clair :
				le fait que le graphe n√©cessite une notion de hi√©ararchie (avec certains shortest paths qui se concentrent sur certains noeuds) pour que les CH fonctionnent
				le lien entre cette notion de hi√©rarchie, et le fait que l'ordering contracte en dernier les nodes "int√©ressants"
				QUESTION 1 = pourquoi faut-il que les nodes "importants" soient contract√©s en dernier pour que la CH r√©sultante soit efficace ?
					raison pragmatique = les nodes importants vont cr√©er beaucoup de shortcuts
				QUESTION 2 = comment les heuristiques utilis√©es pour l'ordering arrivent-elles √† contracter en dernier les nodes "importants" ?
				Pourquoi limiter le quotient des hops est un facteur int√©ressant ?
					piste = peut-√™tre non pas pour l'efficacit√© de la CH, mais plut√¥t pour faciliter l'ordering ?
					piste = pour faciliter l'utilisation des CH pour transit-node routing ?
					piste = pour acc√©l√©rer l'unpacking ?
				Quel est l'int√©r√™t/impact du troisi√®me facteur utilis√© notre moteur (maxSearchSpaceSize) ?
		Notes et ressources algorithmiques √† mettre ailleurs :
			Cette page a un point de vue int√©ressant sur les tas :
				https://docs.python.org/fr/3.7/library/heapq.html#theory
				(o√π on voit le tas comme le r√©sultat final d'un tournoi sportif ! ‚Äî √† chaque √©tage, les "vainqueurs" de l'√©tage pr√©c√©dent, avec le gagnant en haut de la pyramide)
			Quelques ressources int√©ressantes pour le calcul d'iti :
				site:i11www.iti.kit.edu filetype:pdf route
				site:i11www.iti.kit.edu/_media/members filetype:pdf
				https://i11www.iti.kit.edu/_media/members/torsten_ueckerdt/torsten_ueckerdt-habilitationsschrift.pdf
					graph coloring
			RESSOURCES DIVERSES :
				Pas directement li√© √† l'algorithmique des graphes :
					http://blog.notdot.net/tag/damn-cool-algorithms
				WOW : extraordinaire source de vid√©os :
					https://www.youtube.com/channel/UCBvRy0gXDEQaf_dl8UUAE7g/videos
						les vid√©os ALGO 2020
						chacun a sans doute un papier qui va avec !
					https://www.youtube.com/watch?v=URhbkWsi_vo
						ESA.7.8 Space efficient, Fast and Exact Routing in Time dependent Road Networks
					https://www.youtube.com/watch?v=iCuP0OqQD5c
						(pour ma culture)
						ESA.4.3 Dynamic Matching Algorithms in Practice
					https://www.youtube.com/watch?v=quP6ebMjT5E
						(pour ma culture)
						ESA.1.3 Compact Oblivious Routing in Weighted Graphs
					https://www.youtube.com/watch?v=sG7KsfrxbKA
						(pour ma culture)
						ESA.5.9 Single Source Shortest Paths and Strong Connectivity in Dynamic Planar Graphs
					https://www.youtube.com/watch?v=3lMruK5e3uE
						ESA.7.4 Lower Bounds and Approximation Algorithms for Search Space Sizes in Contraction Hierarchies
					https://www.youtube.com/watch?v=8uBkJBTQ3Og
						ATMOS.3.1 Time Dependent Alternative Route Planning
					https://www.youtube.com/watch?v=N4EfmVqxKWA
						ATMOS.1.1 Cheapest Paths in Public Transport Properties and Algorithms
					https://www.youtube.com/watch?v=LMdQCo4vREc
						ATMOS.6.2 Customizable Contraction Hierarchies with Turn Costs
				Ressources papiers / biblio :
					https://github.com/papers-we-love/papers-we-love
					https://lamport.azurewebsites.net/pubs/time-clocks.pdf
					https://www.youtube.com/channel/UCoj4eQh_dZR37lL78ymC6XA/videos
				Cette ressource a plein de choses chouettes sur les impl√©mentations des graphes :
					https://www.researchgate.net/publication/47843190_Algorithms_and_Data_Structures_The_Basic_Toolbox
			Notes en lien avec la graph theory :
				http://glaros.dtc.umn.edu/gkhome/projects/gp/publications
					les publications metis sur le graph partitioning
				introduction au graph partitioning en deux parties, dans ce qui semble √™tre un cours sur le parallel programming :
					https://people.eecs.berkeley.edu/~demmel/cs267/lecture18/lecture18.html
					https://people.eecs.berkeley.edu/~demmel/cs267/lecture20/lecture20.html
					----------------------------------------
					https://people.eecs.berkeley.edu/~demmel/cs267/
					Applications of Parallel Computers (spring 1996)
					Le lien avec le calcul parall√®le est que si on partitionne un graphe, on peut traiter ses diff√©rentes partitions en parall√®le :
						We think of a node n in N as representing an independent job to do, and weight Wn as measuring the cost of job n.
						An edge e=(i,j) in E means that an amount of data We must be transferred from job j to job i to complete the overall task
						Avec ce formalisme, les edges qui "traversent" des partitions repr√©sentent des besoins de synchro entre des jobs.
					Almost all the algorithms we discuss are only for graph bisection, i.e. they partition N = N1 U N2.
					They are intended to be applied recurively, again bisecting N1 and N2, etc., until the partitions are small and numerous enough.
				des ressources int√©ressantes, notamment sur les algos parall√®les ou les IOs :
					https://www.cs.cmu.edu/afs/cs/project/pscico-guyb/realworld/www/slidesS18/
					https://www.cs.cmu.edu/afs/cs/project/pscico-guyb/realworld/www/indexS18.html
				papier sur la compression de graphe (ressource qui explique CSR) :
					https://www.cs.cmu.edu/afs/cs/project/pscico-guyb/realworld/www/slidesS18/compression6.pdf
					----------------------------------------
					il y a quelques exemples de graphe publiquement accessibles
					cas concret d'optimisation de graphe avec Netflix (90% de m√©moire en moins) :
						https://netflixtechblog.com/netflixgraph-metadata-library-an-optimization-case-study-6cc7d5eb2946
					autre cas concret = rex de facebook sur graph reordering :
						https://research.fb.com/publications/compressing-graphs-and-indexes-with-recursive-graph-bisection/
					CSR = cache friendly method of storing graph in memory
					Apparemment, la notation CSR est utilis√©e pour les out-edges, on parle de CSC pour les in-edges.
					Int√©ressante comparaison des diff√©rentes repr√©sentations d'un graph (adjmatrix, edge-list, adj-list, CSR) :
						scan_graph
						get_neighbours
						is_edge
						insert_edge
						delete_edge
						----------------------------------------
						on y voit notamment que CSR n'est pas tr√®s efficace s'il faut ajouter/supprimer des edges
					Ils pr√©sentent CSR comme un format non-compress√© (et effectivement, c'est le cas).
					Pour compresser, on tire parti des particularit√©s du graphe (e.g. dans le web, les liens proches ont tendance √† r√©f√©rencer les m√™mes pages)
					La conclusion est un r√©sum√© int√©ressant :
						Compressed representations important (memory isn‚Äôt free)
						Efficient representations important
						Tradeoffs between space-efficiency and fast decoding
						Formats should be amenable to parallelization
						Real world graphs are highly compressible!
						Real world graphs have much smaller separators than expected
				un papier int√©ressant sur graph partitioning (par recursive bisection) :
					https://ldhulipala.github.io/papers/RecursiveBisection.pdf
				impl√©mentations libres de CH :
					https://gist.github.com/systemed/be2d6bb242d2fa497b5d93dcafe85f0c
						listing de plein d'impl√©mentations
					https://github.com/UDST/pandana/
						C++
						a l'air √† peu pr√®s propre
					https://courses.cs.washington.edu/courses/cse332/20wi/homework/contraction/
						peut-√™tre qu'il y aura une impl√©mentation ici
					Arf, je suis √† peu pr√®s s√ªr d'√™tre tomb√© sur une impl√©mentation "p√©dagogique" en python, mais je ne la retrouve pas
			visualisation √† faire (un jour peut-√™tre) :
				plotter le temps de contraction en fonction du pourcentage du node (on d√©marre √† 0%, un node √† 10% correspond au fait qu'il reste 90% de nodes √† contracter)
				je m'attends √† ce que √ßa augmente fortement √† la fin
		Notes sur la complexit√© Dijkstra :
			https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm#Running_time
			La page anglaise de Dijkstra a une explication int√©ressante de la complexit√© en la s√©parant en deux termes :
				TERME 1 = E √ó Tdecreasekey = on va mettre √† jour le tentative cost  (et possiblement decrease la Key d'un node dans la queue) autant de fois qu'il y a d'edges
				En effet, vu :
					1. que chaque noeud n'est settled qu'une fois
					2. que c'est quand on settle un n≈ìud qu'on relaxe ses out-edges, et donc qu'on peut mettre √† jour la cl√© du head-node dans la queue,
					3. que chaque out-edge est unique √† un tail-node donn√©...
				Alors il s'ensuit qu'on decreasekey au pire une fois par (out-)edge dans le graphe.
				----------------------------------------
				TERME 2 = V √ó Textractminimum = √† chaque fois qu'on s'appr√™te √† settle un n≈ìud, il faut rechercher celui √† co√ªt min (ce qui se fait en temps constant) et L'EXTRAIRE, ce qui se fait en Textractminimum
			Avec une priority queue classique, les deux T sont en  log(V), ce qui donne la version "de base" (i.e. sans utiliser de fibonacci-heap) de la complexit√© de Dijkstra = |E+V| √ó log(V)
		Qui utilise les CH ?
			graphhopper
			la lib python dont j'ai oubli√© le nom
			navitia
			osrm
		Les trucs int√©ressants (√† retenir) du talk d'Hannah BAST :
			diff√©rence entre :
				relaxer un edge particulier = calculer le co√ªt pour joindre le head-node via cet edge, et mettre √† jour le tentative-cost du head-node si l'edge l'am√©liore.
				settle un node = sortir un node de la priority-queue (son tentative-cost devient alors son cost d√©finitif)
				----------------------------------------
				en gros, dijkstra alterne entre les deux :-)
			17:00 La raison pour laquelle on veut contacter les autoroutes en dernier, c'est qu'elles participeront sans doute √† beaucoup de plus courts chemins.
				Si on les contactait en premier, on ajouterait d√®s le d√©but beaucoup de shortcuts.
			19:40 avec un bon orderering, le nombre de shortcuts est cens√© √™tre petit devant le nombre d'edges originaux.
				TODO = le v√©rifier.
			47:00 en fait, exploiter la hi√©rarchie du network, c'est √©galement l'id√©e qui est derri√®re l'am√©lioration des transfer patterns √† √©chelle nationale (qui utilise du clustering)
		Note sur la notion de hi√©rarchie :
			il y a plusieurs fa√ßons de voir cette notion de hi√©rarchie, mais l'id√©e ma√Ætresse est que toutes les sections n'ont pas la m√™me valeur
			une vision n¬∞1 qui me parle beaucoup = notion de fr√©quence de section :
				pour un graphe √† N nodes, on peut calculer exhaustivement tous les N¬≤ PCC possibles entre les N¬≤ paires de noeuds possibles
				l'id√©e est que certaines sections "contribuent" √† plus de PCC que d'autres
				dit autrement, les PCC passent statistiquement plus par certaines sections que d'autres
				par exemple, des sections de l'autoroute A10 appara√Ætront sur beaucoup de PCC, alors que la petite Impasse-machin √† Trifouillis n'appara√Ætra que sur les PCC en provenance (ou √† destination) de l'impasse
				on peut donc consid√©rer que les sections de l'A10 sont PLUS IMPORTANTES que celle de l'impasse
				si on calcule le "score" de chaque section, on peut donc classer les sections des moins importantes aux plus importantes, et √©tablir une hi√©rarchie
				statistiquement, il sera plus important de rejoindre facilement les sections de l'A10 que celle de l'impasse, d'o√π la n√©cessit√© d'attribuer √† ces sections importantes un rank √©lev√©
			une vision n¬∞2 que j'ai trouv√©e dans un papier (je sais plus lequel) :
				tout PCC d'une longueur suffisamment √©lev√©e va obligatoirement chercher √† rejoindre un r√©seau restreint (e.g. le r√©seau d'autoroute)
				dit autrement, √† partir d'une longueur de chemin suffisamment √©lev√©e, TOUS les PCC vont emprunter une autoroute
				du coup, les autoroutes sont plus importantes que d'autres sections, et il est int√©ressant de pouvoir les emprunter plus facilement (donc de leur attribuer un rank √©lev√©)
		notes de compr√©hension CH> TODO = mettre √ßa quelque part :
			Ooooh, je vienx de comprendre un principe important des CH !
			contexte = j'ai acquis cette compr√©hension en essayant de forger un graphe dans lequel contracter deux nodes cons√©cutivement n'ajoute pas les m√™mes shortcuts selon l'ordre dans lequel on les contracte
			La cons√©quence : si un noeud "pas important" est en haut de la hi√©rarchie, on va "perdre du temps" √† le rejoindre en relaxant les edges qui y m√®nent (vu que le noeud est haut dans la hi√©rarchie)
			or, comme le noeud n'est pas important, rejoindre ce noeud... ne servira √† rien : il ne sera JAMAIS (ou rarement) un meeting-node !
			Une autre fa√ßon de voir les choses = une propagation dijkstra CH va (grosso-modo) settle/relaxer tous les noeuds/edges en haut de la hi√©rarchie...
			... alors si on veut en settle/relaxer PEU, il faut que tous ces noeuds soient UTILES (et contribuent √† beaucoup de plus courts chemins)
			dit autrement :
				un noeud important (qui contribue √† beaucoup de plus courts chemins) doit √™tre plac√© en haut de la hi√©rarchie, certes...
				... mais c'est surtout vrai dans l'autre sens : un noeud non-important, s'il est plac√© en haut de la hi√©rarchie, ajoute des edges √† relaxer inutiles !
			d'o√π la phrase de Hannah BAST dans un de ses calls : "pour que les CH marchent, il faut qu'il y ait une notion de hi√©rarchie dans le graphe"
				il faut que certains nodes soient plus importants que d'autres... (car comme on va souvent les settle vu qu'ils sont en haut, ils ont plus de chance d'√™tre des meeting-nodes)
				...et donc que certains nodes soient MOINS importants que d'autres
				et placer les nodes en BAS de la hi√©rarchie a pour effet de diminuer le nombre d'edges √† relaxer lors de la propagation
			note : une autre fa√ßon d'expliquer l'influence de l'ordering
				l'int√©r√™t si on contracte un node plus tard, c'est que certains de ses voisins V (vers lesquels le node N √©tait sur le plus court chemin) auront disparu
				du coup, le fait que N contribue √† un plus court chemin vers V n'entraine plus l'ajout d'un shortcut
				on pourrait objecter : mais dans ce cas, il faudra peut-√™tre ajouter un shortcut de N vers "le successeur de V vers lequel la contraction de V a cr√©√© un shortcut" ?
				deux √©l√©ments de r√©ponse :
					d'abord : oui, si le couple N+V est sur le plus court chemin vers ce successeur (de A vers F, dans mon exemple), alors il est logique qu'il y ait un shortcut au final (pour conserver les PCC sur le remaining-graph)
					mais quand on y regarde de plus pr√®s, le fait d'avoir contract√© un node avant "augmente" la distance entre le pr√©d√©cesseur et le successeur lors de la local-search (c'est l'une des raisons pour laquelle le local-search est si longue)
					du coup, on a plus de chanes de trouver un plus court chemin entre A et F qui contourne le couple N+V
			encore une autre fa√ßon de voir les choses pour enfoncer le clou :
				dans mon exemple, N contribue aux plus courts chemins vers X, MAIS pas aux plus courts chemins vers les successeurs de X
				dit autrement : les seuls plus courts chemins auxquels N contribue sont les plus courts chemins vers X
				du coup, contracter X *avant* N permet de le supprimer du graphe... et N ne contribue donc plus √† aucun plus court chemin !
		Tentative de compr√©hension de la construction des shortcuts ULTRA :
			SECTION 3.1 = OVERVIEW :
				on prend tous les journeys J1 (de station √† station, i.e. sans diffusion/rabattement) qui utilisent exactement UN transfert
					(NdM : a priori, ces journeys comprennent donc l'ensemble des transferts possibles, qui sont les CANDIDATES TRANSFERS pour les shortcuts)
					√† ce stade, m√™me si c'est pas hyper clair, probablement que les transferts sont sur le graphe COMPLET (et non uniquement les transfers restreints, du GTFS)
				pour chaque journey J1, on regarde s'il existe un autre journey J2 (qui, lui, peut avoir de la diffusion ou du rabattement) :
					on supprime alors ceux qui sont domin√©s par un autre journey
					en effet, leurs transfers ne sont pas n√©cessaires, vu que le journey qui domine (et son transfer) ira de toutes fa√ßons plus vite
					les journeys dominants sont des witness (car ils t√©moignent que le transfer du journey domin√© n'est pas n√©cessaire)
				un point important : les witness de station √† station peuvent utiliser le graphe pi√©ton (et pas uniquement les transferts)
					note : en premier abord, √ßa semble contredire le fonctionnement d√©crit pr√©c√©demment, mais en r√©alit√©, il faut distinguer :
						le set J1 (qui n'utilise pas le graphe pi√©ton, en dehors du transfert entre ligne A et ligne B)
						le set J2 (qui utilise le graphe pi√©ton, y compris pour rabattement/diffusion)
					dit autrement si pour faire le journey Sa>T>Sb (o√π A et B sont des lignes, Sa est un stop particulier de la ligne A ; et Sb de la ligne B et T le transfer pi√©ton entre les deux lignes)
					alors on s'autorise √† faire (Sa) T1>Sx>T...>S...>T2 (Sb)
					c'est √† dire que m√™me en partant de Sa (et en arrivant √† Sb), on s'autorise √† ne pas prendre le TC √† Sa, mais plut√¥t √† marcher au d√©part ou √† l'arriv√©e
					si on fait √ßa, √ßa veut dire que le transfert T (de Sa>T>Sb) est peut-√™tre domin√© par un autre transfert (ci-dessous, T3) :
						Sa>T1>Sx>T2>Sy>T3>Sb
					√† la limite, il peut m√™me √™tre domin√© par un journey sans TC (on fait √† pied le trajet entre Sa et Sb) :
						Sa>T1>Sb
					ou m√™me par un trajet sans transfert (on rejoint √† pied la ligne B) :
						Sa>T1>Sx>Sb
				L'id√©e cl√©, c'est que si, pour un journey donn√©, on ne trouve aucun witness, alors son transfer est n√©cessaire, et le shortcut est ajout√© au graphe.
			Impl√©mentation :
				naif = √©num√©rer tous les journeys du set J1, et pour chacun, rechercher des witness dans le set J2
				na√Øf impraticable car il y a trop de journeys
				utilisation d'un rRaptor modifi√© (pour limiter √† deux rounds = un seul transfert pi√©ton)
					-> TODO = comprendre rRaptor
					rRaptor = r√©pond √† des one-to-all rangeQueries
				un point qui semble important : le self-pruning assure que beaucoup de dominated journeys sont √©limin√©s rapidement
			Algorithme 1 = ULTRA transfer shortcut computation :
				INPUT = le GTFS et le graphe pi√©ton G (V,E)
				OUTPUT = un sous-graphe G' (S, E') qui ne comporte que les vertices des stops, et que le subset des edges E' n√©cessaires pour conserver les PCC
				ETAPES : l'algorithme it√®re sur tous les stops S :
					dijkstra one-to-many = calculer la distance pi√©tonne entre S et tous les autres stops
					classer tous les trips qui partent de S par departure_time
					it√©rer sur les trips qui partent de S, par ordre INVERSE (i.E. on commence l'it√©ration par le DERNIER trip qui part de S)
						(round 1) pour chaque trip, collecter les routes (y compris celles qui impliquent de la marche √† pied unrestricted), et marquer tous les stops d√©sservis
						relaxer les transfers de ces stops (pas clair : en utilisant le graphe pi√©ton complet ? Ou juste les transfers du GTFS ? EDIT : a priori, MR-‚àû implique je suppose l'utilisation de TOUT le graphe)
						(round 2) scanner les routes qui ont √©t√© mises √† jour par les transfers
						r√©cup√©rer les stops qui ont √©t√© mis √† jour -> ce sont les unwitnessed candidates
					plus de d√©tail sur ce dernier point : si parmi les stops mis √† jour, le stop est atteint via un candidate journey (i.e. un journey qui ne n√©cessite pas de rabattement/diffusion)...
					... alors le transfer de ce journey est prouv√© comme n√©cessaire, et ajout√© aux shortcuts
				√† noter que la phrase suivante laisse √† penser que les "shortcuts" ne sont pas des shortcuts au sens CH, mais simplement des edges directs de station √† station :
					Thus, we extract the intermediate transfer of the found candidate journey and add it as an edge to the shortcut graph
				je pense qu'√† ce stade, les "shortcuts" sont simplement des "edges"
			SECTION 3.2 = impl√©mentation details :
				ils utilisent une variante de MCR (MR-‚àû) ; id√©alement, il faudrait que je lise le papier
				la relaxation des stops utilise donc a priori TOUT le graphe pi√©ton
				autre phrase en vrac :
					As shown for MCR [10], the transfer relaxation is often the bottleneck of multi-modal routing algorithm
				ULTRA se parall√©lise naturellement bien, vu qu'on traite chaque stop ind√©pendament les uns des autres
				NdM : on stoppe la contraction lorsque le core (graphe non-contract√©) atteint un certain degr√© -> on peut tradeoff le preprocess-time vs. le query-time
			rRAPTOR sur le papier original = section 4.2 :
				on part d'un stop S, sur un range de temps Œî
				conceptuellement, il s'agit "simplement" de collecter toutes les heures de d√©part œÑ des trips qui sont dans Œî (ce qui forme le set Œ®), puis de lancer un RAPTOR "classique" pour chaque œÑ ‚àà Œ®
				en pratique, parmi les r√©sultats de ces multiples RAPTOR, certains seront domin√©s
					(e.g. s'il y a deux TC cons√©cutifs qui partent de S √† 10h10 et 10h15 mais font arriver tous les deux √† 11h √† destination, alors le premier est domin√© par le second)
				du coup, on ordonne tous les œÑ ‚àà Œ® par heure de d√©part D√âCROISSANTE, et quand on travaille sur un œÑ donn√©, on conserve la meilleure heure d'arriv√©e aux stops d'un œÑ pr√©c√©dent
				ainsi, si on voit qu'on arrive plus tard, on sait d√©j√† que le œÑ actuel est domin√© par un œÑ ult√©rieur, et on peut le pruner
				autre note d'optimisation = on peut parall√©liser en d√©coupant Œ® en plusieurs morceaux
			QUESTIONS :
				comment sont calcul√©s les journeys J2 ? √áa revient √† r√©soudre le probl√®me pour lequel on con√ßoit ULTRA √† la base !
					d'ailleurs, on pourrait peut-√™tre utiliser les hubs pour acc√©l√©rer cette √©tape ?
				on semble assimiler shortcut √† transfer, dans la description de la section 3.1...
					or, pour moi, les shortcuts sont des notions li√©es aux CH, et les transfers peuvent repr√©senter l'agr√©gat de plusieurs shortcuts
			Bon, clairement, le d√©tail du calcul des shortcuts ULTRA n'est pas clair, et m√©riterait que je le bosse un peu plus pour le comprendre.
				je peux donner les quelques cl√©s que je comprends, toutefois
				le parcours se fait sur l'ensemble de la plage de temps (en ordre inverse), comme rRAPTOR
		Tentative de compr√©hension de la construction du bucket-CH :
			SECTION 4 = query algorithms :
				TL;DR : bucket-CH = une fa√ßon de r√©pondre efficacement aux queries de type one-to-many ou many-to-one
				explication de bucket-CH :
					step1 = calcul de la CH d'un graphe donn√© (i.e. ordering + contraction)
					step2 = √† partir du set des targets (ici, du set des stops), attribuer √† chaque vertex V du graphe d'un bucket contenant les distances de V √† chaque target
						la phrase suivante n'est pas claire : This is done by adding every target to the buckets of all vertices in its reverse CH search space.
					step3 = ... pas clair non plus
				bref, pour le moment, bucket CH n'est pas clair
			La section 3.2 de ULTRA-trip-based formule diff√©remment la requ√™te bucket-CH :
				(mais je ne comprends toujours pas comment le bucket-CH est calcul√©)
				https://drops.dagstuhl.de/opus/volltexte/2020/13140/pdf/OASIcs-ATMOS-2020-4.pdf
				First, a standard CH query from s to t with departure time œÑdep is performed.
				This yields :
					the minimal arrival time œÑmin at the target via a direct transfer,
					the forward CH search space Vs of s,
					and the backward CH search space Vt of t.
				If, œÑmin < ‚àû holds, then we have found an s-t-journey with arrival time œÑmin that uses zero trips
				Afterwards, we evaluate the buckets containing vertex-to-stop transfer times for vertices in Vs, which provides us with the arrival time œÑarr(s,v) for each stop v with œÑarr(s,v) ‚â§ œÑmin.
					c'est √ßa qui n'est pas clair : si j'ai D√âJ√Ä un bucket qui contient les vertex-to-sop transfer-times, je n'ai qu'√† l'√©valuer pour conna√Ætre l'heure √† laquelle je peux arriver √† chaque stop :thinking-face:
				Similarly, we evaluate the buckets containing stop-to-vertex transfer times for vertices in Vt, in order to obtain transfer times œÑt(v,t) for all stops v with œÑt(v,t) ‚â§ œÑmin‚àíœÑdep
				EDIT : j'ai l'impression qu'il s'agit surtout de conna√Ætre le temps d'initialisation de chaque stop
					(mon interrogation reste : j'ai l'impression que c'est simplement œÑ + dur√©e(SOURCE, STOP)  pour chaque stop...)
					√† noter qu'on dirait qu'on ne garde que les stops qui sont plus int√©ressants qu'un trajet direct de S √† T
					(c'est logique : si je veux aller de Trifouillis √† Denfert, et que je mets 1h √† pied, inutile que je m'int√©resse aux stops qui sont √† plus d'1h de Trifouillis, ou √† plus d'1h de Denfert)
			Aha, ce papier m'aide un peu plus √† comprendre :
				https://drops.dagstuhl.de/opus/volltexte/2020/13137/pdf/OASIcs-ATMOS-2020-1.pdf
				je pense que la cl√©, c'est que je peux attribuer la distance d'un vertex v √† l'un des stops, UNIQUEMENT s'il est dans son reverse-search-space !
				dit autrement : tous les vertices vdu graphe ne peuvent pas se voir attribuer un bucket avec la distance qui relie v √† chaque stop s
				du coup, √ßa me fait une premi√®re raison qui fait que je ne peux pas simplement "lire dans son bucket" la plus courte distance de V √† chaque stop S : il se peut que certains stops ne soient pas dans le bucket
				et de toutes fa√ßons, il y a une deuxi√®me raison plus importante : le bucket de V ne contient pas la PLUS COURTE distance de V √† Sx !
					EDIT : possiblement, si en fait... si c'est bien le cas, c'est uniquement la premi√®re raison qui fait qu'on ne peut pas juste "lire" la distance dans le bucket
						(en effet, a priori, s'il y a un chemin entre Sx et V dans le backward search-space, c'est le PCC par construction)
					----------------------------------------
					en effet, consid√©rer que la distance de V √† Sx lue dans le bucket est la plus COURTE distance revient √† dire que V √©tait le meeting-point du bidirectional dijkstra
					or, V est en quelque sorte juste "un meeting-point parmi d'autres", et il se peut qu'un chemin encore plus court existe, ayant pour meeting-point un autre node N dans le G‚Üë de V
					(du coup, la formulation des explications d'ULTRA est plus claire)
			Ma compr√©hension de l'algo bucket-CH :
				preprocessing = je veux pr√©calculer les buckets de chaque vertex du graphe :
					STEP1 = obtenir une CH du graphe :
						calculer l'ordering + la contraction du graphe
						on dispose d'une CH (i.e. d'un graphe contract√© sur lequel on peut run des queries)
					STEP2 = it√©rer sur chaque stop S du graphe :
						faire un reverse-dijkstra qui part du stop
						ce reverse-dijkstra explorera l'int√©gralit√© des vertices du downard graph G‚Üì
						(un point important, c'est que G‚Üì ne contient pas TOUS les vertices du graphe initial G)
						pour chaque vertex V de G‚Üì, on stocke la distance entre V et S dans le bucket de V
					au final, √† l'issue de ces deux steps, chaque vertex V du graphe dispose d'un bucket √† N items, o√π N = |STOPS|
					le bucket d'un vertex V contient N items = la distance entre V et chacun des N stops
					√† noter (et c'est le point qui me manquait pour comprendre l'algo) que certains items pourront √™tre √©gaux √† +‚àû !!!
					en effet, pour un stop donn√© Sx et un vertex donn√© V, si jamais V n'√©tait pas dans le graphe downward G‚Üì du stop Sx, alors V ne conna√Ætra pas sa distance √† Sx (et restera √† +‚àû)
					c'est ce qui explique que la query n'est pas simplement "je regarde dans le bucket de V pour conna√Ætre la distance jusqu'√† chaque stop"
				query = √† partir d'un vertex V du graphe, je veux conna√Ætre sa distance √† chacun des stops du graphe :
					STEP3 = prenons pour exemple un stop en particulier Sx (mais en r√©alit√©, c'est bien la distance vers CHACUN DES STOPS qui m'int√©ressse)
						je fais un forward-search en partant de V
						√† chaque fois que je relaxe un node N (y compris le premier node relax√© = V), je regarde si dans le bucket de N, il y a une distance vers Sx
						si oui, √ßa veut dire que j'ai trouv√© (en quelque sorte) un meeting-point du bidirectional-dijkstra : c'est N
						la distance (candidate) entre V et Sx est alors d(V‚ÜíN) + d(N‚ÜíSx)
							avec d(V‚ÜíN) qui est donn√©e par le foward-search depuis V
							et d(N‚ÜíSx) qui est "lue" dans le bucket-CH de N, calcul√©e lors du preprocess
						la somme des deux me donne donc une distance candidate entre V et Sx...
						... mais √ßa n'est pas forc√©ment la plus courte !
						Na√Øvement, il faut que je continue √† relaxer les nodes jusqu'√† ce que je j'ai explor√© TOUT le forward-search-space partant de V
						(en pratique, peux m'arr√™ter d√®s que la distance de V √† N (o√π N est le prochain noued settled) est sup√©rieure √† la plus courte distance de V √† Sx d√©j√† trouv√©e)
					note : si dans le bucket de V je trouve une distance D0 vers Sx (i.e. V √©tait bien dans le reverse-search-space de Sx), √áA NE VEUT PAS DIRE que D0 est la PLUS COURTE DISTANCE vers Sx
						en effet, le fait que V a bien Sx dans son bucket veut "juste" dire qu'on a trouv√© un meeting-point du bidirectional dijkstra
						mais peut-√™tre qu'il existe un meilleur meeting point ailleurs dans le forward-search-space de V
					Et du coup, en faisant √ßa pour tous les stops en m√™me temps, il me suffit d'un forward-search-space depuis V pour conna√Ætre la meilleure distance de V √† chacun des stops S
			NdM : il faut voir si le preprocess servant √† calculer les bucket-CH est lourd ou pas, mais conceptuellement, je pense qu'on peut remplacer bucket-CH par hub-labeling
				(en effet, il permet lui aussi de conna√Ætre la distance entre V et tous les stops, de fa√ßon relativement efficace)
		TODO = p√©renniser mes notes ci-dessous sur GTFS:
			En fait, dans le format GTFS, l'√©l√©ment central, c'est le trip (= le voyage d'un v√©hicule physique) :
				le trip est associ√© √† une route, uniquement pour conna√Ætre des m√©ta-infos sur la route (p.ex. son nom) | les m√©ta-infos de chaque route sont d√©finies dans routes.txt
				le trip est associ√© √† une s√©rie de stops (c'est impl√©ment√© dans l'autre sens : chaque stop a un trip_id, et une s√©rie de stops donn√© ayant le m√™me trip_id constitue les "stops d'un trip")
				√† la diff√©rence de ce qui est attendu par les papiers de recherche, le format GTFS permet tout √† fait de d√©finir des trips d'une m√™me route ayant des stops diff√©rents
				dit comme √ßa, on dirait que le GTFS permet de d√©finir des trips d'une m√™me route, ayant un set de stops diff√©rents ?
				Effectivement, la doc du format GTFS ne mentionne pas explicitement que les stops des trips d'une m√™me route doivent √™tre identiques :
					https://developers.google.com/transit/gtfs/reference?hl=fr#dataset_files
					Itin√©raires en transports en commun. Un itin√©raire est un ensemble de trajets pr√©sent√©s aux usagers comme relevant du m√™me service.
		ULTRA> Ce papier donne la d√©finition du core CH utilis√© dans ULTRA :
			TODO = mettre √† jour mes notes sur le sujet (et au passage, merger ma branche de notes sur ULTRA)
			https://ad-publications.cs.uni-freiburg.de/GIS_personal_FS_2015.pdf
			Dans le chapitre 3.1 (Customizable CH), sous-section "Accelerating Customization"
			TL;DR : le core, ce sont les nodes qu'on a d√©lib√©r√©ment choisi de ne pas contracter lors de la contraction (pour √©viter que celle-ci diverge).
			c'est un tradeoff qui ralentit un peu le query-time pour acc√©l√©rer le preprocessing-time
				l'extr√™me dans un sens, c'est si on requ√™te sur un graphe : le preprocess est instantan√©, mais la query est lente = celle d'un dijkstra bi-directionnel classique
				l'extr√™me dans l'autre sens, c'est si on requ√™te sur un graphe compl√®tement contract√© :  le preprocess est le plus lent possible, mais la query grandement acc√©l√©r√©e
			note : √† mon avis, lorsqu'on fait une query sur un graphe partiellement contract√©, on modifie la contrainte "ne garder que les edges vers les nodes de rank sup√©rieurs" en :
				"ne garder que les edges vers les nodes de rank sup√©rieurs, ou les edges depuis/vers des nodes appartenant au core"
			et m√™me, la phrase suivante de l'article laisse √† penser que c'est m√™me plus subtil :
				Optimal query answering can still be guaranteed when considering edges between core nodes in the bidirectional Dijkstra run as well.
		Ce qui n'a pas sa place dans mes notes bibliographiques sur CH :
			Goal-directed technique = algos orientant la recherche de la solution "vers" la cible (e.g. A*)
			Il y a √©galement une d√©finition et quelques exemples de techniques) dans [ce papier](https://publikationen.bibliothek.kit.edu/1000014952) :
				Goal-Directed Approaches direct the search towards the target t by preferring edges that shorten the distance to t and by excluding edges that cannot possibly belong to a shortest path to t. Such decisions are usually made by relying on preprocessed data.
			Dans un arbre, il n'existe qu'un seul chemin possible entre deux noeuds.
		Graphes :
			Tout probl√®me o√π on affecte des ressources (e.g. cr√©neau horaire) √† des acteurs (e.g. prof) en respectant des contraintes d'incompatibilit√© se mod√©lise bien en coloriant un graphe (bipartite ?) o√π :
				les edges sont les contraintes,
				les acteurs sont les n≈ìuds
				les ressources sont les couleurs des noeuds
			Exemple = cr√©ation de planning
			Nombre chromatique born√© min par taille du sous graphe induit complet, et born√© max par degr√©max+1
		ROUTING> Nouveaux papiers √† imprimer :
			https://www.microsoft.com/en-us/research/wp-content/uploads/2010/12/punchTR.pdf  2010 "Graph partitioning with natural cuts"
			https://drops.dagstuhl.de/opus/volltexte/2020/13145/pdf/OASIcs-ATMOS-2020-9.pdf  <--- customizable contraction hierarchies with turn costs !
			https://arxiv.org/pdf/1311.3144.pdf   <-- r√©cent survey sur les techniques de graph partitioning
			https://arxiv.org/abs/1906.11811   Am√©lioration du partitionnement WCH !!!
			https://drops.dagstuhl.de/opus/volltexte/2020/12947/   Am√©lioration de TCH !!!
			http://perso.ens-lyon.fr/eric.thierry/Graphes2009/thorup.pdf
			https://i11www.iti.kit.edu/extra/publications/dssw-erpa-09.pdf  (m√™me s'il est plus ancien et plus court que l'autre survey, il peut √™tre int√©ressant tout de m√™me)
			papier ancien (test-of-time award) mais int√©ressant sur la parall√©lisation de dijkstra :
				Delta-Stepping: A Parallel Single Source Shortest Path Algorithm.
			https://hal.inria.fr/hal-01359084v2
			https://hal.inria.fr/inria-00471716
			Public transit routing with unrestricted walking (ATMOS 2017)
			http://tpajor.com/assets/paper/ddpww-cmjp-13.pdf  (v√©rifier que je ne l'ai pas d√©j√† imprim√©)
			papier 2 = Personalized Route Planning in Road Networks
				https://ad-publications.cs.uni-freiburg.de/GIS_personal_FS_2015.pdf
				https://dl.acm.org/doi/10.1145/2820783.2820830
			papier 3 = Contraction Hierarchies on Grid Graphs
				https://link.springer.com/chapter/10.1007/978-3-642-40942-4_21
				https://ad-publications.cs.uni-freiburg.de/KI_gridCH_S_2013.pdf
			lire le papier que mon coll√®gue a link√© + le papier sur WCH
				https://arxiv.org/pdf/1910.12726.pdf
				id√©e cl√© = au lieu de stocker la TTF compl√®te, on stocke juste les chemins diff√©rents
				pour le moment, rien de nouveau, si ce n'est une optimisation de la taille des graphes TCH
					en effet, les TTFs sont expand de fa√ßon lazy
					√ßa se fait donc au prix d'un cache, qu'il faudra remplir petit √† petit
					p√©riode donc "froide" (et pas forc√©ment parallel-friendly...)
					seul avantage = on ne remplit pas le cache avec les itis inutilis√©s
				am√©lioration potentielle de la contraction WCH
				dixit Kevin "plus de section closed in real-time graph" -> on a d√©j√† tout ce qu'il faut pour √ßa !
				elimination tree au lieu d'un simple dijkstra bidirectionnel
			https://i11www.iti.kit.edu/extra/publications/dw-lbrdg-07.pdf      (ALT)
			https://drops.dagstuhl.de/opus/volltexte/2017/7897/pdf/OASIcs-ATMOS-2017-3.pdf
				Time-dependent + customizable !!
			https://www.cs.bgu.ac.il/~elkinm/thorup_zwick.do.pdf
			am√©lioration autour du v√©lo (bicriteria) :
				https://drops.dagstuhl.de/opus/frontdoor.php?source_opus=5458
			J'ai plusieurs papiers sur le hub-labelling et leur application dans les PTN que je n'ai pas imprim√©s. Dans le papier de Laurent Viennot, il s'agit de 1, 2,8, 10, 20. De plus, Viennot utilise 9 en pratique
			Par ailleurs, 19 a l'air int√©ressant
			https://i11www.iti.kit.edu/_media/teaching/theses/ma-sauer-18.pdf ??
			https://drops.dagstuhl.de/opus/frontdoor.php?source_opus=13145
			https://www.researchgate.net/publication/40646194_Combining_Hierarchical_and_Goal-Directed_Speed-Up_Techniques_for_Dijkstra%27s_Algorithm
				Combining Hierarchical and Goal-Directed Speed-Up Techniques for Dijkstra's Algorithm
				2010
				PDF librement accessible
				papier qui semble tr√®s int√©ressant et qui est une revue des techniques permettant de COMBINER les CH avec des techniques goal-directed
				(j'y vois notamment l'int√©r√™t de pouvoir garder la puissance de personnalisation des goal-directed techniques, et la vitesse des CH ?)
			https://www.researchgate.net/publication/288889992_Fast_Computation_of_Isochrones_in_Road_Networks
				Fast Computation of Isochrones in Road Networks
				2015
		ROUTING> les choses √† faire en rapport avec le routing :
			BIBLIO> sujets de routing qui me restent √† d√©fricher :
				dijkstra multi-crit√®re
					√ßa a l'air d'√™tre un domaine riche : rechercher label-setting dijkstra / label-correcting dijkstra etc.
					e.g. Multi-criteria Shortest Paths in Time-Dependent Train Networks
					https://link.springer.com/chapter/10.1007/978-3-540-68552-4_26
					utilis√© √† la query (mais ce n'est PAS le MC-dijkstra utilis√© pour le calcul des TP)
					----------------------------------------
					le survey de 2015 indique "Multicriteria Label Setting" avec plusieurs r√©f√©rences.
						au lieu d'associer un tentative-cost √† chaque node, on associe un bag de labels non-domin√©s (avec autant de labels dans le bag que de crit√®res)
						la priority-queue trie par label plut√¥t que par tentative-cost
					le survey de 2015 indique √©galement "Multicriteria Label Correcting" avec d'autres r√©f√©rences.
				QUESTION : label-correcting vs. label-setting ?
					√ßa r√©pond √† quelle question ?
					c'est utilis√© dans quel contexte ?
					lequel est meilleur ?
				TODO = comprendre pourquoi RAPTOR est du ressort du dynamic-programming ?
				TODO = comprendre pourquoi DIJKSTRA peut-√™tre vu comme du ressort du dynamic-programming ?
				----------------------------------------
				Highway hierarchies, et les diff√©rences avec CH
				A*, landmark, triangle inequality = ALT = https://www.microsoft.com/en-us/research/wp-content/uploads/2004/07/tr-2004-24.pdf
					https://www.cs.princeton.edu/courses/archive/spr09/cos423/Lectures/reach-mit.pdf
					ALT : https://www.microsoft.com/en-us/research/wp-content/uploads/2004/07/tr-2004-24.pdf
				Papiers issus de ALGO 2019 : https://algo2019.ak.in.tum.de/index.php/algo-program
					A Graph- and Monoid-Based Framework for Price-Sensitive Routing in Local Public Transportation Networks
						https://drops.dagstuhl.de/opus/volltexte/2019/11424/
					Robust Routing in Urban Public Transportation: How to Find Reliable Journeys Based on Past Observations
						https://hal.inria.fr/hal-00871734/document
				C'est int√©ressant : une partie des papiers concerne l'aide √† la conception de r√©seaux de transports publics :
					https://drops.dagstuhl.de/opus/volltexte/2018/9713/
					https://drops.dagstuhl.de/opus/volltexte/2018/9721/
				Il y a aussi des papiers orient√©s "voiture autonome", ou avions.
				Public Transit Routing with Unrestricted Walking  (note : plus ancien qu'ULTRA)
					https://drops.dagstuhl.de/opus/volltexte/2017/7891/
				Fast and Exact Public Transit Routing with Restricted Pareto Sets
					https://www.researchgate.net/publication/330098838_Fast_and_Exact_Public_Transit_Routing_with_Restricted_Pareto_Sets
				A label correcting algorithm for the shortest path problem on a multi-modal route network.
					http://www.lix.polytechnique.fr/Labo/Leo.Liberti/sea12c.pdf
			comprendre comment la g√©n√©ration du hubs-labeling fonctionne :
				on dirait que l'algo utilis√© par hub-labeling est pruned landmark labeling + random sampling
				il semble au moins mentionn√© ici : http://www.vldb.org/pvldb/vol11/p445-li.pdf
				voir aussi : https://www.researchgate.net/publication/300450292_Hub_Labels_Theory_and_Practice
				et √©galement : https://www.researchgate.net/publication/221131726_A_Hub-Based_Labeling_Algorithm_for_Shortest_Paths_in_Road_Networks
			Pas facile = trouver o√π mettre ce genre d'informations :
				int√©ressant (mais difficile √† classer) = calculer le PCC de longueur maximale :
					https://files.inria.fr/gang/road/diameter.html
				√† r√©f√©rencer quelque part :
					https://tristramg.eu/histoire-calcul-iti/
				pages expliquant le fonctionnement de Valhalla  :
					https://valhalla.readthedocs.io/en/latest/route_overview/
					https://valhalla.readthedocs.io/en/latest/thor/path-algorithm/
					https://github.com/valhalla/valhalla/blob/master/docs/sif/dynamic-costing.md
			Papier sur un nouveau algo dans la famille des RAPTOR :
				https://gitmemory.cn/repo/alexdray86/McRAPTOR
				Our work consists of a robust journey planner, which finds journeys between stops within a 15km radius around Zurich Hbf and computes their probability of success based on the distribution of delays over the past years.
				Given a source stop, a target stop, a latest acceptable arrival time, and a lowest acceptable probability of success for the entire journey, our journey planner finds the journey whose departure time is latest among all acceptable options.
		BIBLIO ‚Äî SAUVEGARDE :
			Les trucs √† ajouter √† ma biblio :
				Stefan FUNKE
					https://www.researchgate.net/publication/357617040_Distance_Closures_Unifying_Search-_and_Lookup-based_Shortest_Path_Speedup_Techniques
						Distance Closures: Unifying Search- and Lookup-based Shortest Path Speedup Techniques
						unifier les approches search (e.g. CH) et les approches lookup (e.g. hub-labeling)
						this allows for new and (practically very attractive) space-time tradeoffs for shortest-path computation
						leur permet d'avoir des r√©sultats sur le planet OSM soit un graphe avec 500M nodes
					https://www.researchgate.net/publication/353564222_Sublinear_Search_Spaces_for_Shortest_Path_Planning_in_Grid_and_Road_Networks
						Sublinear Search Spaces for Shortest Path Planning in Grid and Road Networks
						In this paper, we use the very intuitive notion of bounded growth graphs to describe road networks and also grid graphs. We show that this model suffices to prove sublinear search space
						Analyse du search-space size th√©orique pour : CH, transit node, et hub-labels
					https://www.researchgate.net/publication/351860228_A_Lower_Bound_for_the_Query_Phase_of_Contraction_Hierarchies_and_Hub_Labels_and_a_Provably_Optimal_Instance-Based_Schema
						A Lower Bound for the Query Phase of Contraction Hierarchies and Hub Labels and a Provably Optimal Instance-Based Schema
						We prove a Œ©(n) lower bound on the query time for contraction hierarchies (CH) as well as hub labels,
						Pr√©curseur du papier ci-dessus ?
					https://www.researchgate.net/publication/345609814_Scalable_Unsupervised_Multi-Criteria_Trajectory_Segmentation_and_Driving_Preference_Mining
						Scalable Unsupervised Multi-Criteria Trajectory Segmentation and Driving Preference Mining
						M√©thode d'analyse de jeux de trajectoires, pour trouver (p.ex.) des choses int√©ressantes sur les routes, ou bien les pr√©f√©rences d'un utilisateur.
					https://www.researchgate.net/publication/343909768_Seamless_Interpolation_Between_Contraction_Hierarchies_and_Hub_Labels_for_Fast_and_Space-Efficient_Shortest_Path_Queries_in_Road_Networks
						Seamless Interpolation Between Contraction Hierarchies and Hub Labels for Fast and Space-Efficient Shortest Path Queries in Road Networks
						We propose a conceptually simple, yet very effective extension of the highly popular Contraction Hierarchies (CH) speedup technique improving query times for shortest paths in road networks by one order of magnitude with very modest space overhead.
					https://www.researchgate.net/publication/337255087_Improved_Contraction_Hierarchy_Queries_via_Perfect_Stalling
						Improved Contraction Hierarchy Queries via Perfect Stalling
						d√©riv√© de CH, 33% plus rapide que CH (avec un pr√©-calcul, pas clair s'il y a de l'overhead par rapport √† CH)
					https://www.researchgate.net/publication/336975544_Alternative_Routes_for_Next_Generation_Traffic_Shaping
						Alternative Routes for Next Generation Traffic Shaping
						Alternative route computations so far have mostly been considered as producing a small set of reasonable routes for a human driver to select from. In the not too distant future most cars will be self-driving, and choosing from a very large set of alternative routes might become a very effective means for balancing traffic loads on the road network. Therefore, in this paper we consider the problem of finding a large set of reasonable alternative routes.
					https://www.researchgate.net/publication/332883401_Identifying_Preferred_Areas_in_Road_Networks
						Identifying Preferred Areas in Road Networks
						We consider the problem of identifying preferred areas on a map which are characterized by a conjunction of minimum or maximum distance conditions from or to (classes of) points of interest.
						En gros, on cherche √† trouver facilement les endroits d'une carte qui v√©rifient un set de plusieurs contraintes simultan√©es (e.g. moins de 15 min d'une cr√®che, moins de 10 min de courses, moins de 2h des parents, moins de 4h des grands parents)
					https://www.researchgate.net/publication/330095787_Alternative_Multicriteria_Routes	
						Alternative Multicriteria Routes
					https://www.researchgate.net/publication/327637915_Generating_Concise_and_Robust_Driving_Directions
						Generating Concise and Robust Driving Directions
						We consider the problem of generating concise and robust driving directions that avoid overly detailed turn-by-turn instructions as long as one is not too close to the final destination.
						Our approach is based on a deliberate selection of cities as landmarks that are likely to appear on road signs along the route.
						For a route from Stuttgart to Flensburg, the route description could read "Go towards Frankfurt, then Kassel, then Hanover, then Hamburg". A
					https://www.researchgate.net/publication/315499814_URAN_A_Unified_Data_Structure_for_Rendering_and_Navigation
						URAN: A Unified Data Structure for Rendering and Navigation
						plut√¥t que d'utiliser CH d'un c√¥t√©, et mapnik de l'autre, le papier propose un unique jeu de donn√©es servant √† la fois au routing et √† la carto
					https://www.researchgate.net/publication/312078433_Map_Simplification_with_Topology_Constraints_Exactly_and_in_Practice
						Map Simplification with Topology Constraints: Exactly and in Practice
						(c'est un sujet carto, plut√¥t)
					https://www.researchgate.net/publication/312426473_Deducing_individual_driving_preferences_for_user-aware_navigation
						Deducing individual driving preferences for user-aware navigation
						Analyse des trajets pass√©s de l'utilisateur pour d√©duire ses pr√©f√©rences.
					https://www.researchgate.net/publication/300217991_Provable_Efficiency_of_Contraction_Hierarchies_with_Randomized_Preprocessing
						Provable Efficiency of Contraction Hierarchies with Randomized Preprocessing
						Analyse th√©orique des CH.
					https://www.researchgate.net/publication/282948617_Placement_of_Loading_Stations_for_Electric_Vehicles_No_Detours_Necessary
						Placement of Loading Stations for Electric Vehicles: No Detours Necessary!
						we consider the problem of placing as few loading stations as possible so that on any shortest path there are sufficiently many not to run out of energy.
					https://www.researchgate.net/publication/290119360_Energy-Efficient_Routing_Taking_Speed_into_Account
						Energy-Efficient Routing: Taking Speed into Account
						calcul de routes energy-efficient
						we do not only make use of variation of the routes to save energy but also allow variation of driving speed along the route to achieve energy savings.
					https://www.researchgate.net/publication/261851619_Sequenced_route_queries_Getting_things_done_on_the_way_back_home
						Sequenced route queries: Getting things done on the way back home
						We consider the problem of planning an optimal route (quickest or shortest) that visits facilities of the respective type on the way home
						En gros, trouver le "plus court chemin qui rentre chez moi qui passe par une banque"
				Sabine STORANDT
					https://www.researchgate.net/publication/357618850_Polyline_Simplification_under_the_Local_Fr'echet_Distance_has_Subcubic_Complexity_in_2D
						Polyline Simplification under the Local Fr\'echet Distance has Subcubic Complexity in 2D
						simplification de polylines
					https://www.researchgate.net/publication/357018928_FISSION_Practical_Algorithms_for_Computing_Minimum_Balanced_Node_Separators
						FISSION: Practical Algorithms for Computing Minimum Balanced Node Separators
					https://www.researchgate.net/publication/355920589_Barrier-Free_Pedestrian_Routing_with_Contraction_Hierarchies
						Barrier-Free Pedestrian Routing with Contraction Hierarchies
						Trouver des chemins qui traversent de l'indoor et de l'outdoor (e.g. aller de chez soi √† tel magasin dans un grand centre commercial)
						Faire ceci, en ne s'int√©ressant qu'aux trajets accessibles en fauteuil roulant.
					https://www.researchgate.net/publication/335212094_PATHFINDER_Storage_and_Indexing_of_Massive_Trajectory_Sets
						PATHFINDER: Storage and Indexing of Massive Trajectory Sets
					https://www.researchgate.net/publication/328944331_Sensible_edge_weight_rounding_for_realistic_path_planning
						Sensible edge weight rounding for realistic path planning
						Comment arrondir les poids des edges d'un graphe (pour minimiser l'espace n√©cessaire au stockage, ou le co√ªt de leur manipulation) d'une fa√ßon intelligente.
					https://www.researchgate.net/publication/324540575_Region-Aware_Route_Planning
						Region-Aware Route Planning
						Faire des trajets d'un point A √† un point B en passant par "une r√©gion" au milieu
				Julian DIBBELT
					https://www.researchgate.net/publication/346089870_Modeling_and_Engineering_Constrained_Shortest_Path_Algorithms_for_Battery_Electric_Vehicles
						Modeling and Engineering Constrained Shortest Path Algorithms for Battery Electric Vehicles
						Since battery capacities are limited, fastest routes are often infeasible. Instead, users are interested in fast routes on which the energy consumption does not exceed the battery capacity. For that, drivers can deliberately reduce speed to save energy. Hence, route planning should provide both path and speed recommendations.
				Daniel DELLING :
					https://www.researchgate.net/publication/328519301_Traffic-Aware_Routing_in_Road_Networks
						Traffic-Aware Routing in Road Networks
						Avoir de meilleures routes qui contournent le traffic (e.g. ne pas passer par des stations services, ou des zones r√©sidentielles, sans non plus les d√©gager du graphe)
				Renato WERNECK
					https://www.researchgate.net/publication/298393314_Accelerating_Local_Search_for_the_Maximum_Independent_Set_Problem
						Accelerating Local Search for the Maximum Independent Set Problem
					https://www.researchgate.net/publication/317756946_Finding_near-optimal_independent_sets_at_scale
						Finding near-optimal independent sets at scale
				Peter SANDERS
					https://arxiv.org/abs/2011.02601
						Fast, Exact and Scalable Dynamic Ridesharing
						adresse le probl√®me de choisir comment attribuer des chauffeurs de VTC (e.g. uber) √† des clients qui en ont besoin
					https://www.researchgate.net/publication/337878107_Real-time_Traffic_Assignment_Using_Engineered_Customizable_Contraction_Hierarchies
						Real-time Traffic Assignment Using Engineered Customizable Contraction Hierarchies
						sert √† l'urban planning = conna√Ætre l'encombrement d'un r√©seau routier donn√© au vu des itin√©raires qui vont √™tre effectu√©s dessus
					https://arxiv.org/abs/1907.03535
						More Hierarchy in Route Planning Using Edge Hierarchies
						Plut√¥t que de cr√©er une hi√©rarchie de nodes (comme dans les CH), √©tudie la question de cr√©er une hi√©rarchie d'edges.
						Travail encore prospectif : Our findings indicate that this can lead to considerably smaller search spaces in terms of visited edges. Currently, this rarely implies improved query times so that it remains an open question whether edge hierarchies can lead to consistently improved performance.
				Dominik SCHULTES (et d'autres)
					https://www.researchgate.net/publication/227728083_Bidirectional_A_Search_on_Time-Dependent_Road_Networks
						Bidirectional A* Search on Time-Dependent Road Networks
						article de 2012, mais qui peut s'av√©rer int√©ressant :+1:
				Tobias Z√úNDORF :
					https://www.researchgate.net/publication/354898825_Robustness_Generalizations_of_the_Shortest_Feasible_Path_Problem_for_Electric_Vehicles
						Robustness Generalizations of the Shortest Feasible Path Problem for Electric Vehicles
						Probl√®me adress√© = quel sont les chemins qu'on peut faire avec tel niveau de batterie, tout en gardant un peu de marge pour √™tre robuste aux erreurs d'estimation sur la batterie restante, ou sur le temps de trajet.
				Dorothea WAGNER :
					https://www.researchgate.net/publication/358088043_An_Axiomatic_Approach_to_Time-Dependent_Shortest_Path_Oracles
						An Axiomatic Approach to Time-Dependent Shortest Path Oracles
						we can provide time-dependent distance oracles that provably exhibit subquadratic preprocessing time and space, query time sublinear on the network size or the actual Dijkstra rank of the query at hand, and small stretch factor (approximation error).
					https://www.researchgate.net/publication/350160090_Nearest-Neighbor_Queries_in_Customizable_Contraction_Hierarchies_and_Applications
						Nearest-Neighbor Queries in Customizable Contraction Hierarchies and Applications
						Pas clair quel est le probl√®me adress√©...
					https://www.researchgate.net/publication/350114463_Space-Efficient_Fast_and_Exact_Routing_in_Time-Dependent_Road_Networks
						Space-Efficient, Fast and Exact Routing in Time-Dependent Road Networks
						CATCHup = impl√©mentation de TDCH
						https://github.com/kit-algo/catchup
						https://github.com/kit-algo/rust_road_router/
					https://www.researchgate.net/publication/335862773_Faster_and_Better_Nested_Dissection_Orders_for_Customizable_Contraction_Hierarchies
						Faster and Better Nested Dissection Orders for Customizable Contraction Hierarchies
				Ben STRASSER
					https://www.researchgate.net/publication/336868609_A_with_Perfect_Potentials
						A* with Perfect Potentials
						Probl√®me adresser = quelle heuristique utiliser pour A* ?
				Christos ZAROLIAGIS
					SA PAGE A AJOUTER = https://www.researchgate.net/profile/Christos-Zaroliagis
					https://www.researchgate.net/publication/355343436_Incentivizing_Truthfulness_in_Crowdsourced_Parking_Ecosystems
						Incentivizing Truthfulness in Crowdsourced Parking Ecosystems
						Probl√®me adress√© = quand on utilise de l'info crowdsourc√©e sur la disponibilit√© des parkings, comment √™tre robuste √† son manque de fiabilit√© ?
					https://www.researchgate.net/publication/353395576_Time-Dependent_Alternative_Route_Planning_Theory_and_Practice
						Time-Dependent Alternative Route Planning: Theory and Practice
						papier r√©cent (juillet 2021)
				Spyros KONTOGIANNIS
					SA PAGE √Ä AJOUTER = https://www.researchgate.net/profile/Spyros-Kontogiannis
					https://www.researchgate.net/publication/340864671_Renewable_Mobility_in_Smart_CitiesTheMOVESMART_Approach
						Renewable Mobility in Smart Cities:TheMOVESMART Approach
						MOVESMART = projet europ√©en autour de la mobilit√©
				Tim ZEITZ
					SA PAGE √Ä AJOUTER = https://www.researchgate.net/scientific-contributions/Tim-Zeitz-2134414785
					https://www.researchgate.net/publication/340805727_Efficient_Route_Planning_with_Temporary_Driving_Bans_Road_Closures_and_Rated_Parking_Areas
						Efficient Route Planning with Temporary Driving Bans, Road Closures, and Rated Parking Areas
						We study the problem of planning routes in road networks when certain streets or areas are closed at certain times. For heavy vehicles, such areas may be very large since many European countries impose temporary driving bans during the night or on weekends.
						In this setting, feasible routes may require waiting at parking areas, and several feasible routes with different trade-offs between waiting and driving detours around closed areas may exist.
					https://arxiv.org/abs/1910.12526
						A Fast and Tight Heuristic for A* in Road Networks
						Utiliser CH pour l'heuristique A* !
						On garde la possibilit√© de "customizer" le trajet gr√¢ce √† A*, mais en continuant √† r√©pondre rapidement, gr√¢ce √† de bons choix d'heusistiques avec CH.
				AUTEURS INDEPENDANTS :
					https://drops.dagstuhl.de/opus/volltexte/2021/13785/
						O'Reach: Even Faster Reachability in Large Graphs
						Probl√®me address√© = Given a directed graph and two vertices s and t, can s reach t via a path?
					https://arxiv.org/abs/2102.01540
						Targeted Branching for the Maximum Independent Set Problem
						Probl√®me address√© = trouver un maximum independent set
					https://arxiv.org/abs/2107.00761
						On the Bike Spreading Problem
						Probl√®me adress√© = comment attribuer les v√©los aux stations de sorte que les flux d'usage les r√©partissent √©quitablement (pour √©viter leur concentration dans certaines zones)
					https://drops.dagstuhl.de/opus/volltexte/2021/14872/
						Towards Improved Robustness of Public Transport by a Machine-Learned Oracle
						Probl√®me adress√© = comment √©valuer la robustness aux retards de trajets TC.
						an existing pool of solutions (i.e., public transport plans) can be significantly improved by finding a number of new non-dominated solutions, providing better and different trade-offs between robustness and travel time
					https://drops.dagstuhl.de/opus/volltexte/2021/14584/
						Bi-Objective Search with Bi-Directional A*
					https://dl.acm.org/doi/10.1145/3474717.3483955
						Most Diverse Near-Shortest Paths
						Probl√®me adress√© = trouver des routes alternatives les plus diverses tout en ne s'√©cartant trop pas du temps de parcours minimal.
					https://dl.acm.org/doi/10.1145/3474717.3483652
						Weighted Stackelberg Algorithms for Road Traffic Optimization
						Probl√®me address√© = comment guider ses utilisateurs de fa√ßon √† ne pas d√©grader le traffic collectif du r√©seau, tout en √©tant suffisamment bons individuellement pour que l'utilisateur continue d'utiliser l'outil.
					https://dl.acm.org/doi/10.1145/3474717.3483961
						Robust Routing Using Electrical Flows
						Probl√®me address√© = calculer des routes alternatives qui soient robustes aux changements des conditions traffic.
					https://dl.acm.org/doi/abs/10.1145/3474717.3484259
						Dual-Attention Multi-Scale Graph Convolutional Networks for Highway Accident Delay Time Prediction
						Probl√®me address√© = essayer de mod√©liser et pr√©voir √† quel point un accident donn√© va perturber la circulation.
					https://dl.acm.org/doi/10.1145/3474717.3484267
						Tiering in Contraction and Edge Hierarchies for Stochastic Route Planning
						Probl√®me adress√© = Stochastic route planning = route-planning o√π le poids des edges n'est pas d√©terministe, mais suit une loi de probabilit√©s.		
					https://dl.acm.org/doi/10.1145/3474717.3483913
						Hierarchical Neural Architecture Search for Travel Time Estimation
						AI pour estimer le travel time des edges
					https://arxiv.org/pdf/2110.06456.pdf
						Updating Street Maps using Changes Detected in Satellite Imagery
						Probl√®me adress√© = comment utiliser les images satellites pour mettre √† jour les cartes routi√®res.
					https://dl.acm.org/doi/10.1145/3474717.3484262
						Online Route Replanning for Scalable System-Optimal Route Planning
						Semble s'int√©resser √† la question de retarder son d√©part pour avoir de meilleures conditions de trajet.
					https://dl.acm.org/doi/abs/10.1145/3474717.3484253
						Predicting Road Accident Risk Using Geospatial Data and Machine Learning (Demo Paper)
				Theodoros CHONDROGIANNIS
					SA PAGE √Ä AJOUTER = https://www.researchgate.net/profile/Theodoros-Chondrogiannis
					https://www.researchgate.net/publication/305280942_ParDiSP_A_Partition-Based_Framework_for_Distance_and_Shortest_Path_Queries_on_Road_Networks
						ParDiSP: A Partition-Based Framework for Distance and Shortest Path Queries on Road Networks
						Probl√®me adress√© = proposer un framework √† la foix efficace pour trouver le plus court CHEMIN et la plus courte DISTANCE (alors que traditionnellement, les technos efficaces pour l'un ne sont pas les plus efficaces pour l'autre).
					https://www.researchgate.net/publication/285235064_Alternative_Routing_k-Shortest_Paths_with_Limited_Overlap
						Alternative Routing: k-Shortest Paths with Limited Overlap
						Probl√®me address√© = trouver k routes alternatives, suffisamment diff√©rentes de la route optimale.
					https://www.researchgate.net/publication/339418272_Finding_k-shortest_paths_with_limited_overlap
						Finding k-shortest paths with limited overlap
						Probl√®me address√© = trouver k routes alternatives, suffisamment diff√©rentes de la route optimale.
					https://www.researchgate.net/publication/345579081_Finding_The_Most_Preferred_Path
						Finding The Most Preferred Path
						Probl√®me address√© = √©tant donn√© un utilisateur ayant ses petites habitudes de trajet, comment trouver un PCC sur une requ√™te quelconque, qui trouve le bon compromis entre arriver rapidement et lui faire passer par des chemins connus ?
						Essentially, the objective of optimal routing is no longer to reach the destination as fast as possible but to travel as much as possible inside the preferred network.
					https://dl.acm.org/doi/10.1145/3468791.3468844
						Online Landmark-Based Batch Processing of Shortest Path Queries
						Probl√®me adress√© = mutualiser le travail sur un batch de shortest-path queries, pour y r√©pondre efficacement, sans preprocessing.
			AUTRE SOURCE √† ajouter ::
				https://www.sciencedirect.com/journal/transportation-research-procedia/vol/62/suppl/C = Transportation Research Procedia
				https://dl.acm.org/toc/trnps/2020/54/5 = Transportation Science
			Il y a quelques papiers d'analyse du traffic (donc plut√¥t destin√© √† Tomtom) :
				https://dl.acm.org/doi/abs/10.1145/3474717.3483975
				https://dl.acm.org/doi/abs/10.1145/3474717.3483650
			Revu les titres des papiers des principales conf√©rences 2021 :
				ALENEX 2021 = https://www.siam.org/conferences/cm/program/accepted-papers/alenex21-accepted-papers
				SEA 2021 = https://sea2021.i3s.unice.fr/node/21.html
				ATMOS 2021 = http://algo2021.tecnico.ulisboa.pt/ATMOS2021/index.html
				ESA 2021 = http://algo2021.tecnico.ulisboa.pt/ESA2021/accepted.html
				SIGSPATIAL 2021 = https://sigspatial2021.sigspatial.org/accepted-papers/
			Lib pour mesurer √† quels points deux graphes sont diff√©rents :
				https://www.researchgate.net/publication/333675235_GEDLIB_A_C_Library_for_Graph_Edit_Distance_Computation
			Regarder d'un peu plus pr√®s ce vieil article de 2010 ?
				https://www.researchgate.net/publication/221131526_Distributed_Time-Dependent_Contraction_Hierarchies
				Distributed Time-Dependent Contraction Hierarchies
			Ce livre est possiblement pas mal :
				https://www.amazon.fr/Sequential-Parallel-Algorithms-Data-Structures/dp/3030252086
				Sequential and Parallel Algorithms and Data Structures: The Basic Toolbox Reli√© ‚Äì 11 septembre 2019
				L'un des auteurs est Peter SANDERS
	PERSO> NOTE : wiki technique waze = https://wazeopedia.waze.com/wiki/USA/Main_Page/Technical_links
	PERSO> Une info importante de CCH = ils peuvent customizer un graphe Europe (certes, petit : 18M vertices + 42M edges) en moins d'une seconde \o/
	PERSO> NOTES WCH et CCH (graphes cordaux, notamment) :
		Un point de vue de CCH sur les contraction hierarchies, qui est int√©ressant :
			Many techniques work by adding extra edges called shortcuts to the graph that allow query algorithms to bypass large regions of the graph efficiently
			Donc en gros, ce qui fait que les CH marchent bien, c'est (entre autres) que les shortcuts "regroupent" plusieurs edges.
			Un point qui serait int√©ressant : sur N requ√™tes sur les CH, regarder le nombre d'edges du PCC (ou bien relax√©s) en contract√© d'une part, et en expanded d'autre part
			(l'id√©e sera de montrer qu'on n'a explor√© que 200 edges contract√©s, mais que √ßa repr√©sentait 2000 edges r√©els)
		plus g√©n√©ralement, si je veux vraiment bien comprendre les CH, il me faut un framework pour jouer avec :
			contracter un graphe
			mesurer des choses sur le graphe contract√©
			lancer N requ√™tes d'itin√©raires et les inspecter
			voire lancer TOUTES les requ√™tes d'itin√©raires possible pour (p.ex.) mesurer le nombre moyen de n≈ìuds settled, et voir sa variation en fonction de l'ordering ?
			etc.
		NOTE sur la witnessless-contraction, et le lien avec les graphes coraux :
			Apr√®s la contraction de N, ses voisins forment une clique !
			En effet, √† la diff√©rence des contractions CH de notre moteur, le graphe est undirected
			Il n'y a pas de notion de pr√©d√©cesseur/successeur vu qu'il n'y a pas de directionalit√© : il n'y a que des "voisins" qui sont tous √©quivalents.
			Du coup, dans un graphe undirected, l'√©quivalent des couples {pr√©d√©cesseur+successeur} est un couple {voisin1+voisin2} pour CHAQUE voisin
			Du coup, on ajoutera des edges entre CHAQUE paire de voisin, ce qui formera une clique.
			(Ceci n'est plus vrai si la contraction est directed et que √ßa n'est que l'ordering qui est undirected)
		Je comprends mieux l'apport de WCH :
			1. Un moyen d'ordonner efficacement les nodes sans m√©trique (alors que le papier indique bien que sans m√©trique, l'ordering classique diverge)
			2. les macro instructions pour acc√©l√©rer la customization (sinon, c'est trop long)
			TODO = modifier ma prez CH pour dire qu'on pourrait essayer d'ordonner comme d'habitude (minimiser edge-difference + hierarchy-depth), mais sans tenir compte de la m√©trique, sauf que √ßa diverge
		Note √† la lecture du papier cch : je me suis plant√© sur le crit√®re d'arr√™t ?! Cf. Le haut de la page 16
			Once the radius of one of the two searches is larger than the shortest path found so far, we stop the search because we know that no shorter path can exist.
			Mon crit√®re  √©tait plut√¥t qu'on ne pouvait pas arr√™ter avant que les DEUX radius soient plus large !
			TODO = regarder ce que fait notre moteur ; EDIT : c'est bien "mon" crit√®re qui est suivi : on ne poursuit pas UNE propagation si elle est moins int√©ressante que le meilleur chemin jusqu'ici, mais on continue l'autre
			TODO = regarder ce que fait routing-kit ; EDIT : c'est bien "mon" crit√®re qui est suivi : on n'arr√™te le Dijkstra que si les DEUX propagations sont vides ou plus ch√®res que le meilleur chemin jusqu'ici.
		Autre point important : le stall on demand ne marche pas pour CCH, qui a plus d'edges √† tester que ch (cf. Page 30)
			TL:DR : avec CCH, on a ajout√© beaucoup plus de shortcuts qu'avec CH (√† cause de la witnessless contraction)
				le stall-on-demand a besoin de tester beaucoup d'edges pour choisir d'arr√™ter une propagation sur un vertex non-optimal
				avec CH, il y a peu d'edges, donc le fait d'arr√™ter la propagation t√¥t sur certains apporte des gains suffisants pour compenser le fait d'avoir √† tester des edges
				avec CCH, il y a BEAUCOUP d'edges, donc devoir tester tous ces edges pour savoir si on peut stall devient trop co√ªteux par rapport aux gains apport√©s par arr√™ter la propagation t√¥t
			As already observed by the original CH authors, we confirm that the stall-on-demand heuristic
			improves running times by a factor of 2‚Äì5 compared to the basic algorithm for ‚Äúgreedy+w‚Äù. Interestingly,
			this is not the case with any variant using a metric-independent order. This can be explained by the
			density of the search spaces. While, the number of vertices in the search spaces are comparable between
			metric-independent orders and metric-dependent order, the number of arcs are not comparable and thus
			metric-independent search spaces are denser. As consequence, we need to test significantly more arcs in
			the stalling-test, which makes the test more expensive and therefore the additional time spent in the test
			does not make up for the time economized in the actual search. We thus conclude that stall-on-demand
			is not useful, when using metric-independent orders.
		Am√©lioration de ram = utiliser un meilleur algo de partitioning que metis = InertialFlowCutter (en effet, trouver des s√©parateurs plus petits conduit √† introduire moins de shortcuts)
			https://github.com/kit-algo/InertialFlowCutter
			https://arxiv.org/pdf/1906.11811.pdf
		Les graphes dont tous les s√©parateurs minimaux sont des cliques sont les graphes cordaux.
		Un graphe est cordal ssi il poss√®de un perfect elimination ordering = un ordering tel que chaque sous-graphe {v + voisins de v de rank sup√©rieur √† v} est une clique.
			NOTE : apr√®s la witnessless contraction d'un graphe suivant un ordering Œ±, le supergraphe form√© par {le graphe original + les shortcuts} est chordal
			et le perfect elimination ordering de ce supergraphe chordal est justement l'ordering Œ±
			c'est √† relier avec les explications sur le papier weak CH : le dernier n≈ìud entre deux s√©parateurs forme une clique avec les s√©parateurs qui l'entourent
			et quand il a √©t√© contract√©, les deux s√©parateurs forment une clique √©galement
		Un papier assez ancien, mais qui explique plein de notions qui me seront utiles :
			https://technicalreports.ornl.gov/1992/3445603686740.pdf
			An introduction to chordal graphs and clique trees
			Le sommaire est all√©chant :
				Chrodal graphs (avec comme sous-section : perfect elimination ordering)
				Characterization of clique trees
				Applications, dont Elimination Trees
		Autre papier qui pourrait √™tre int√©ressant au sujet des graphes cordaux :
			https://www.lrde.epita.fr/~adl/ens/theg/theg6.pdf
		La page wikipedia des graphes cordaux a √©galement des infos int√©ressantes :
			https://fr.wikipedia.org/wiki/Graphe_cordal
			Rose, Lueker et Tarjan 1976 (voir aussi Habib et al. 2000) montrent qu'un ordonnancement d'√©limination parfaite d'un graphe cordal peut √™tre trouv√© de mani√®re efficace en utilisant un algorithme [LexBFS]
				LEXBFS = BFS o√π on d√©partage les √©galit√©s de profondeur (le n≈ìud qui gagne est le n≈ìud dont le parent le plus proche de la racine a √©t√© visit√© le premier)
				https://www.irif.fr/~habib/Documents/cours5-2012.pdf
			il est [donc] possible de savoir si un graphe est cordal en temps lin√©aire.
			Une phrase juste en dessous laisse √† entendre qu'il existe PLUSIEURS perfect elimination ordering possibles pour un graphe chordal donn√©.
			Une application de l'ordonnancement d'√©limination parfaite est la recherche d'une clique maximum d'un graphe cordal en temps polynomial. Le probl√®me similaire, mais pour un graphe quelconque, est NP-complet.
			Pour lister toutes les cliques maximales d'un graphe cordal, il suffit de trouver un ordonnancement d'√©limination parfaite, de cr√©er une clique pour chaque sommet v avec les voisins de v venant apr√®s v dans l'ordonnancement d'√©limination parfaite, et de tester pour chacune des cliques ainsi form√©es si est maximale.
		Notes sur le papier CCH :
			le core graphe semble √™tre le graphe de contraction (et j'ai pas des masses analys√© quand et comment on peut arr√™ter la contraction early)
			----------------------------------------
			dans le papier CCH, l'ordering et la contraction se font sur un graphe undirected
			du coup, chaque edge a deux poids : dans un sens et dans l'autre (et si l'edge est √† sens unique, l'un des poids est infini)
			le point int√©ressant, c'est que les poids sont d√©finis par rapport √† l'ordering : on a une m√©trique UPWARD (i.e. les poids des edges dans le sens qui grimpe les ranks) et une m√©trique DOWNWARD
			du coup, on peut se contenter de d√©finir le graphe sans m√©trique en tant que graphe UPWARD uniquement (pas besoin de d√©finir le graphe downward)
			En effet, le graphe downward est construit en inversant le graphe upward, et en lui appliquant la m√©trique downard
		Notes brutes sur une vid√©o sur les treewidths :
			https://www.youtube.com/watch?v=kEnDGTwSDXY
			Treewidth Definitions || @ CMU || Lecture 22b of CS Theory Toolkit
			Commenc√© √† visionner ~2021-12-14
			Treewidth d√©finition Ryan O'Donnell
			----------------------------------------
			Tree = ajout r√©cursif de 1 noeud
			S√©ries parall√®le graphs = ajout r√©cursif de 2 noeuds
			Graphe de treewidth k = ajout r√©cursif de k noeuds
			Tw <= k  ssi G a une triangulation dont la clique maximal est inf√©rieure ou √©gale √† k+1
			Chordal graphs = maximaux pour leur treewidth : si on leur ajoute un edge de plus, on augmente leur treewidth
			Autres √©quivalences : g chordal ssi G a une tree d√©composition o√π chaque bag est une clique ssi G a une perfect √©limination ordering
			Perfect √©limination ordering : en partant d'un graphe vide, et ajoutant les vertex dans l'ordre, au moment de son ajout, chaque nouveau vertex est adjacent √† une k-clique (i.e. √† des vertex connect√©s par une k-clique). Et k est la treewidth du graphe
			Cops and robber : treewidth <= k ssi k+1 cops peuvent gagner (et la tree D√©composition donne une strat√©gie gagnante)
			Treewidth du grid graph= largeur = racine du nombre de n≈ìuds. √áa fait un exemple de graphe simple avec une grande treewidth.
			Ndm : ce jeu de cops and robbers est pas mal pour comprendre intuitivement la treewidth
			Th√©or√®me : si un graphe a une treewidth t, alors il a pour mineur une grille en T puissance 1/9
			Autre vid√©o qui a l'air tr√®s bien : Daniel lokshtanov tree d√©compositions
			Ah, les bags ne contiennent pas que les vertices d'edges !
			En revanche, si on dessine les bags sur le graphe original, ils semblent "connect√©s"
			Notation : width
			Notation : adhesions = l'intersection de deux bags = le recouvrement de deux bags = le set de vertex dans les deux bags (d'o√π le fait que les bags sont "connect√©s" quand on les dessine). Chaque adh√©sion est un edge de T (la tree D√©composition)
			Notation : torso = le graphe induit par un bag, auquel on ajoute les edges entre les vertex des adh√©sions de sorte que les adh√©sions soient des cliques
		NOTES CH UN PEU VRAC SUITE √Ä DIVERSES LECTURES :
			Supporting node = le node dont la contraction est responsable du shortcut.
			Un point important des CH qui contribue au fait que √ßa aille vite : lors d'une query, tous les nodes de rank inf√©rieur √† s ou t n'existent pas (car des shortcuts les remplacent) !
				et du coup, si on a rank√© un node "important" trop bas, on aura d√ª ajouter beaucoup de shortcuts pour le remplacer, ce qui est inefficace
			TODO = utiliser des k-heaps pour la priority queue ?
			Les graphes contract√©s sont acycliques ! Ce sont donc des "arbres orient√©s"?
		NOTES CH :
			l'intro du papier search-space size in contraction hierarchies a plein de liens int√©ressants
			notamment : faire des CHu multicrit√®re permet de r√©duire le nombre de graphes n√©cessaires ? (e.g. pour n'avoir qu'un seul graphe avec et sans p√©age ?)
		Infographie sur les graphes cordaux :
			https://kevinbinz.com/2014/10/08/an-inference-trail-to-chordal-graphs/
			https://kevinbinz.files.wordpress.com/2014/10/ee512-chordal-inference-trail-infographic.png
		Un PDF int√©ressant sur les graphes cordaux :
			(TODO = prendre des notes biblio ?)
			https://www.researchgate.net/publication/236366775_An_introduction_to_chordal_graphs_and_clique_trees
				An introduction to chordal graphs and clique trees
				janvier 1991
				Jean R. S. Blair
				Barry W. Peyton
			note : un truc qui m'avait √©chapp√© : si un n≈ìud appartient √† une clique, alors il est simplicial (vu que ses voisins sont tous connect√©s entre eux et forment une clique eux aussi)
		PERSO> graph theory = nouvelle s√©rie de vid√©os de th√©orie des graphes :
			cha√Æne = Luke POSTLE
				https://www.youtube.com/channel/UCxDmW9HWWPRs07ioPqXsfqA
				il a plusieurs types de vid√©os, celles qui m'int√©ressent sont celles de th√©orie des graphes = https://www.youtube.com/watch?v=YNHwa7n_dms&list=PL2BdWtDKMS6mplieDd_vls0TBX9Fq2jht
			celles que j'ai regard√©es (ou skimm√©es) :
				Graph Theory 6-3: Tree Decompositions and Tree Width
					https://www.youtube.com/watch?v=gCZrasaG0vA&list=PL2BdWtDKMS6mplieDd_vls0TBX9Fq2jht&index=19
				Graph Theory 2-1: An Informal Proof of Brooks Theorem
					https://www.youtube.com/watch?v=Mu3gYvKJuwk&list=PL2BdWtDKMS6mplieDd_vls0TBX9Fq2jht&index=5
				Graph Theory 2-3: Beyond Brooks' Theorem
					https://www.youtube.com/watch?v=ePNUdA-NBqU&list=PL2BdWtDKMS6mplieDd_vls0TBX9Fq2jht&index=7
				Graph Theory 1-4: Coloring and Brooks' Theorem.
					https://www.youtube.com/watch?v=YEzMWEVCx1o
			notes brutes :
				Graph labelling = attribuer un label √† chaque noeud (√©ventuellement en respectant une contrainte)
				Colouring = un labelling particulier.
				C'est aussi un moyen de "d√©couper" le graphe (e.g. en ind√©pendent sets, les colour classes)
				Trouver si un graphe est 2-colorable a  un algo polynomial
				Par contre, √† partir de 3, le probl√®me est np complet.
				M√™me des approximations sont nos compl√®tes : colorier un graphe, c'est difficile !
				Upper bound = degmax + 1 = Th√©or√®me de Brook
				Lower bound de chi(g) = Omega (g) = clique Number of g = maximum size of a clique in g (terminologie : stricte sensu, clique d√©signe uniquement le set de vertex et t pas leur sous graphe induit)
				C'est logique.
				Les deux bounds sont identiques pour le graphe complet
				Les vid√©os suivantes prouvent Brooks, et donnent d'encore meilleurs bornes sup√©rieures si on contraint un peu plus le graphe
	Notes CH √† p√©renniser = (note pour moi √† p√©renniser concernant les CH et plus pr√©cis√©ment le nd-ordering) :
		dans mon grid graphe d'exemple, j'ai DEUX s√©parateurs centraux qui coupent le graphe en deux moiti√©s √©gales : un horizontal de 7 n≈ìuds et un vertical de 3 n≈ìuds
		dans ce cas, le s√©parateur qui contient le MOINS de n≈ìuds et le plus int√©ressant
		en effet, dans ce cas, on r√©partit les chemins int√©ressants = ceux qui passent d'une moiti√© du graphe √† une autre en MOINS de n≈ìuds
		du coup, les n≈ìuds des petits s√©parateurs "contribuent" individuellement √† PLUS de PCC que les n≈ìuds des grands s√©parateurs
		(en n√©gligeant le fait que la taille des moiti√©s identiques change un peu en fonction du nombre de n≈ìud dans le s√©parateur)
		et du coup, les PETITS s√©parateurs doivent √™tre pr√©f√©r√©s aux grands, m√™me si dans les deux cas, le graphe est coup√© en deux moiti√©s √©gales
	Multicriteria CH :
		https://algo2.iti.kit.edu/download/geisberger_badherrenalb08.pdf
		point de vue int√©ressante de Geisberger √† la slide 20 = la notion de "hi√©rarchie" d√©pend du probl√®me :
			le probl√®me "trouver la route la plus rapide" est plus hi√©rarchique que le probl√®me "trouver la route la plus courte"
			(en effet, les autoroutes, et plus g√©n√©ralement les grands axes qui vont vite, seront naturellement en haut de la hi√©rarchie)
			(√† l'inverse, si on cherche √† minmiser le nombre de kilom√®tres, rejoindre les grands axes n'est plus syst√©matiquement le plus int√©ressant)
			du coup, faire du multi-crit√®re interf√®re avec la notion m√™me de hi√©rarchie
	PERSO> Th√©orie des graphes et mes questions √† ma coll√®gue :
		Vid√©o sur la tree-decomposition : treewidth :
			https://www.youtube.com/watch?v=gCZrasaG0vA
		√Ä voir avec ma coll√®gue :
			mineurs
			pathwidth / treewidth
			elimination game
		Ressources int√©ressantes :
			mineurs :
				https://fr.wikipedia.org/wiki/Graphe_planaire#Caract%C3%A9risation_de_Kuratowski_et_de_Wagner
				https://fr.wikipedia.org/wiki/Hom%C3%A9omorphisme_de_graphes
				https://fr.wikipedia.org/wiki/Contraction_d%27ar%C3%AAte
				https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_de_Robertson-Seymour
				https://fr.wikipedia.org/wiki/Mineur_(th%C3%A9orie_des_graphes)
				https://fr.wikipedia.org/wiki/Isthme_(th%C3%A9orie_des_graphes)   isthme = bridge en anglais
				https://www.ams.org/journals/bull/2006-43-01/S0273-0979-05-01088-8/S0273-0979-05-01088-8.pdf   <-- graph minor theory
			d√©compositions arborescentes :
				https://www.labri.fr/perso/courcell/CoursMaster/DecsArbosVersLongue.pdf   <-- D√©compositions arborescentes
				https://fr.wikipedia.org/wiki/D%C3%A9composition_arborescente
				https://fr.wikipedia.org/wiki/Largeur_arborescente
			autres :
				https://fr.wikipedia.org/wiki/Liste_des_algorithmes_de_la_th%C3%A9orie_des_graphes
		Encore un batch de liens wikipedia, en lien avec la treewidth :
			https://fr.wikipedia.org/wiki/Largeur_arborescente
				Pour tout graphe H, on note œâ(H) l'ordre de la plus grande clique de H. La largeur arborescente d'un graphe G est la plus petite valeur prise par œâ(H)-1, parmi toutes les triangulations H de G.
				Les arbres ont largeur d'arbre 1. La clique de taille n a largeur d'arbre n-1. La grille carr√©e de taille n a une largeur d'arbre √©gale √† n2.
				Le concept de d√©composition arborescente a un lien tr√®s fort avec les graphes triangul√©s.
			https://fr.wikipedia.org/wiki/Stable_(th%C3%A9orie_des_graphes)
				un stable ‚Äì appel√© aussi independent set en anglais ‚Äì est un ensemble de sommets deux √† deux non adjacents.
			https://fr.wikipedia.org/wiki/Probl%C3%A8me_du_stable_maximum
				Le [...] maximum independent set problem est un probl√®me d'optimisation qui consiste [...] √† trouver un stable de cardinal maximum, c'est-√†-dire un sous-ensemble de sommets du graphe, le plus grand possible, tel que les √©l√©ments de ce sous-ensemble ne soient pas voisins.
			https://fr.wikipedia.org/wiki/Invariant#En_th%C3%A9orie_des_graphes
				On dit qu'un nombre associ√© √† un graphe est un invariant (de graphe), s'il n'est pas modifi√© par un isomorphisme de graphes. Par exemple, le nombre chromatique est un invariant de graphe.
			https://fr.wikipedia.org/wiki/Triangulation_de_graphe
				On travaille sur un graphe non orient√©. Un graphe est triangul√© si tout cycle de longueur sup√©rieure √† 3 admet une corde. On dit aussi qu'il est cordal.
				La triangulation d'un graphe non triangul√© consiste √† le rendre triangul√©.
				La triangulation d'un graphe n'est pas unique et la recherche de la triangulation optimale (au sens du nombre d'ar√™tes ajout√©es minimum) est un probl√®me NP-Complet.
				L'algorithme le plus utilis√© pour v√©rifier si un graphe est triangul√© est un parcours en largeur lexicographique (dit Lex-BFS).
			https://fr.wikipedia.org/wiki/LexBFS
				semble √™tre un BFS avec des r√®gles sp√©ciales pour r√©soudre les √©galit√©s de profondeur (i.e. pour choisir comment ordonner les n≈ìuds √† la m√™me distance de la racine du BFS)
			https://en.wikipedia.org/wiki/Planar_separator_theorem
				Th√©or√®me int√©ressant, qui peut s'appliquer aux graphes routiers (qui sont presque planaires)
				any planar graph can be split into smaller pieces by removing a small number of vertices.
				Specifically, the removal of O(sqrt(n)) vertices from an n-vertex graph can partition the graph into disjoint subgraphs each of which has at most 2n/3 vertices.
	BIBLIO CH :
		Nouveaux articles √† √©tudier sur CH ?
			Minimum time-dependent travel times with contraction hierarchies (Batz 2013)
			Time-dependent route planning with generalized objective functions (Batz 2012)
				http://algo2.iti.kit.edu/download/slides_batz_ESA12.pdf
				http://algo2.iti.kit.edu/download/gen_obj_func_tch.pdf
		R√©sum√© de techno utilis√©es :
			CH full   = https://algo2.iti.kit.edu/documents/routeplanning/geisberger_dipl.pdf
			CH short  = http://algo2.iti.kit.edu/schultes/hwy/contract.pdf
			TCH full  = https://d-nb.info/1072464543/34
			TCH short = http://algo2.iti.kit.edu/documents/tdch.pdf
			ATCH      = https://algo2.iti.kit.edu/download/sea10_atch.pdf
			WCH       = https://i11www.iti.kit.edu/_media/teaching/theses/weak_ch_work-1.pdf
	NOTES CH √Ä CREUSER :
		quelque chose n'est pas encore clair avec le stalling... :
			le coeur du stalling, c'est que le chemin par lequel on rejoint un node n'est pas optimal, qu'on le sait, et qu'on arr√™te donc la propagation
			√ßa, √ßa va...
			mais comment se fait-il que le chemin optimal ne soit pas trouv√© par la forward-propagation ?
			en effet, dans la mesure o√π tout chemin passant par un noeud de rank inf√©rieur est remplac√© par un chemin allant vers le prochain noeud de rank sup√©rieur...
			alors on devrait tout de m√™me pouvoir emprunter le node avec le bon cost ?
			----------------------------------------
			il faut que je travaille un peu le sujet pour me convaincre de pourquoi c'est comme √ßa
			je sens confus√©ment que c'est li√© au fait que la forward propagation ne settle pas tout le search-space -> il doit donc bien y avoir des noeuds non-settled...
			par ailleurs, peut-√™tre que certes on arrive aux noeuds de rank sup√©rieur, mais que c'est pas √ßa qui compte ?
	Un coll√®gue trouve un nouveau papier qui peut √™tre int√©ressant :
		https://drops.dagstuhl.de/opus/volltexte/2020/13137/pdf/OASIcs-ATMOS-2020-1.pdf
		An Efficient Solution for One-To-Many Multi-Modal Journey Planning
		Combinaison de ULTRA et (R)PHAST
	PERSO> √† mettre quelque part (possiblement, dans mon premier blogpost des CH, qui concernera Dijkstra ?) :
		NOTATION IMPORTANTE POUR DIJKSTRA, lien entre reached/settled/relaxed :
			reached = node adjacent √† un node settled
			(un node est reached lorsqu'on a relax√© l'edge entre son node settle et ce node reached)
			chaque noeud reached est dans la priority-queue, et l'action de settle un node correspond au fait d'extraire le noeud min de la priority-queue
			du coup, avec ce vocabulaire, le crit√®re d'arr√™t du Dijkstra est : "tant qu'il reste des noeuds reached mais pas settled, on continue"
			autre point de vocabulaire = tentative-distance d'un meeting-node
			NOTE : faire un slide de vocabulaire sur Dijkstra ?
		√Ä dire sur la local-search et sur Dijkstra :
			une autre fa√ßon de voir les choses = si le plus court chemin fait 1 km, alors on aura calcul√© TOUS les plus courts chemins possibles dans un rayon de 1 km
			... et idem si le plus court chemin fait 500 km, on calcule beaucoup, beaucoup de plus courts chemins plus petits et inutiles
	Papiers sur les isochrones :
		https://arxiv.org/pdf/1512.09090.pdf
		https://i11www.iti.kit.edu/_media/teaching/theses/ma-buchhold-15.pdf
	Papiers CH int√©ressants, qui concernent les bornes th√©oriques et comportements asymptotiques des CH :
		Lower Bounds and Approximation Algorithms for Search Space Sizes in Contraction Hierarchies
			https://kops.uni-konstanz.de/bitstream/handle/123456789/50799/Blum_2-7tivdcd91s0c9.pdf?sequence=1
			ESA 2020
			Attention : il se concentre sur la LOWER bound (alors que c'est plut√¥t la UPPER bound qui m'int√©resse)
		A Lower Bound for the Query Phase of Contraction Hierarchies and Hub Labels and a Provably Optimal Instance-Based Schema
			https://www.mdpi.com/1999-4893/14/6/164
			2021
			Ici aussi le papier semble se concentrer sur une LOWER bound.
		Search Space Size in Contraction Hierarchies
			https://i11www.iti.kit.edu/_media/teaching/theses/da-columbus-12.pdf  <-- "th√®se" (diplomarbeit) de 130 pages, 2012
			https://www.sciencedirect.com/science/article/pii/S0304397516303176  <-- article 16 pages
			2016
			Semble le plus prometteur
	NOTE TECHNIQUE = La d√©marche (du papier sur le restricted pareto-set) o√π on calcule des itis canoniques, et o√π on n'en d√©vie que peu est int√©ressante :
		si on la g√©n√©ralise, elle permet de r√©pondre √† des questions du genre "est-ce que c'est int√©ressant de gagner 5 minutes de temps d'arriv√©e contre 5 minutes de voiture de plus"
		le keypoint est de savoir calculer des itis canoniques
	NOTES BIBLIO √Ä √âCLUSER :
		Ce papier (2002) semble explicitement d√©di√© au 2-hops labeling :
			Reachability and distance queries via 2-hop labels
			https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.15.2127&rep=rep1&type=pdf
			m√™me si trouver un 2-hop labeling est NP-difficile, leur algo est efficace en pratique, et trouve un 2-hop labeling "presque optimal"
			presque optimal = la taille du 2-hop labeling trouv√© par leur algo est plus grand que la taille optimale d'un facteur qui est au pire logarithmique
		Ce papier (2015) est la derni√®re famille de technique pour calculer des itis TC que je n'ai pas encore explor√©e :
			https://www.microsoft.com/en-us/research/wp-content/uploads/2015/06/ddpw-ptl-15.pdf
			Public Transit Labeling
			S'appuie sur 1. le calcul des 2-hops labels et 2. time-expanded model des timetables
			Apparemment, en mixant les deux, √ßa fournit un moyen tr√®s rapide de r√©pondre aux requ√™tes d'itin√©raires, avec un peu de preprocessing.
			r√©sultat = 2 √† 3 ordres de grandeur plus rapide que RAPTOR pour r√©pondre aux queries !
			apparemment, beaucoup plus rapide aussi que TP, malgr√© un pr√©processing plus court d'un ordre de grandeur
			le preprocessing semble tout de m√™me tr√®s important : ~50h sur Londres
			l'algo utilis√© pour calculer les hubs est un algo "bo√Æte-noire" = RXL (du papier Robust Exact Distance Queries on Massive Networks)
		Ce papier (2014) propose un algo permettant de calculer un 2-hop labeling :
			https://www.microsoft.com/en-us/research/wp-content/uploads/2014/07/complexTR-rev2.pdf
			Robust Exact Distance Queries on Massive Networks
			il est utilis√© comme bo√Æte norie par Public Transit Labeling
		√Ä noter que pour la question du calcul du trajet optimisant le prix, ce papier (2020) est int√©ressant :
			https://drops.dagstuhl.de/opus/volltexte/2020/13149/pdf/OASIcs-ATMOS-2020-13.pdf
			Cheapest Paths in Public Transport: Properties and Algorithms
			le papier semble s'int√©resser aux propri√©t√©s des syst√®mes de tarification, et au lien avec les algos calculant le trajet le moins cher entre deux stops
			le probl√®me est est rendu compliqu√© par le fait que les syst√®mes de tarification sont tr√®s divers et tr√®s diff√©rents les uns des autres
			(rigolo : la traduction de "√† vol d'oiseau" est 'beeline')

