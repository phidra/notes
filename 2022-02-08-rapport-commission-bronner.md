#  Les lumières à l'ère numérique

- **url** = https://www.vie-publique.fr/rapport/283201-lumieres-l-ere-numerique-commission-bronner-desinformation ([PDF](https://www.vie-publique.fr/sites/default/files/rapport/pdf/283201.pdf), [copie locale](./LOCALCOPIES/283201.pdf), md5sum=`2a4350462cb42e943edfefee339c6564`)
- **type** = rapport PDF
- **auteur** = [Gérald BRONNER](https://fr.wikipedia.org/wiki/G%C3%A9rald_Bronner) = professeur de sociologie à Paris-Diderot qui a travaillé sur le complotisme
- **date de publication** = 2022-01-11
- **source** = [vie-publique.fr](https://www.vie-publique.fr/vie-publique-propos), site étatique "qui donne des clés pour comprendre les politiques publiques et les grands débats qui animent la société"
- **tags** = language>none ; topic>politics ; topic>complotisme ; topic=fake-news ; level>beginner

Description succinte de la méthodologie suivie pour analyser ce rapport :

- je peux prendre des notes classiquement
- comme il y a beaucoup d'infos intéressantes dans le rapport, je les cite ici en extrayant des keypoints
- (du coup, ces notes sont essentiellement des citations assorties de keypoints)
- l'idée à terme sera de générer une liste de keypoints pour avoir une synthèse résumant le rapport

Note : j'ai commencé la lecture le 8 février, mais ça va sans doute s'étaler sur plusieurs semaines, vu la longueur, les notes, et le contenu.

**EDIT 1er juin 2022** : le sujet a été commencé, mais est freezé par manque de temps.

REPRISE = mettre en forme toutes les notes du chapitre 2 (car actuellement, elles sont des transferts bruts de mes notes sur téléphone) + poursuivre la lecture/analyse du document.

* [Les lumières à l'ère numérique](#les-lumières-à-lère-numérique)
   * [Introduction](#introduction)
      * [Le chaos informationnel contemporain](#le-chaos-informationnel-contemporain)
      * [Endiguer la propagation de la désinformation](#endiguer-la-propagation-de-la-désinformation)
      * [Renforcer la résilience de la société](#renforcer-la-résilience-de-la-société)
      * [La nécessité d’un espace épistémique commun](#la-nécessité-dun-espace-épistémique-commun)
      * [Objectifs et méthodes de travail de la commission](#objectifs-et-méthodes-de-travail-de-la-commission)
   * [CHAPITRE 1 = Les mécanismes psychosociaux de la désinformation](#chapitre-1--les-mécanismes-psychosociaux-de-la-désinformation)
      * [La représentation des fausses informations sur Internet](#la-représentation-des-fausses-informations-sur-internet)
      * [Effets de la désinformation](#effets-de-la-désinformation)
      * [Distinguer le vrai du faux sur Internet](#distinguer-le-vrai-du-faux-sur-internet)
      * [Conclusion du chapitre 1](#conclusion-du-chapitre-1)
   * [CHAPITRE 2 = Logiques algorithmiques](#chapitre-2--logiques-algorithmiques)

## Introduction

### Le chaos informationnel contemporain

> L’un des faits contemporains les plus marquants est la dérégulation massive du marché de l’information, accélérée par le développement d’Internet.

> Ceci a toutes sortes de conséquences, mais la plus évidente est l’éclosion d’une concurrence généralisée de tous les modèles intellectuels qui prétendent décrire le monde, des plus frustes aux plus sophistiqués. Aujourd’hui, quiconque dispose d’un compte sur un réseau social peut directement apporter une contradiction, sur la question des vaccins par exemple, à un professeur de l’Académie nationale de médecine. Le premier peut même avoir plus d’audience que le second.

**keypoint** = avec Internet, tout le monde a voix au chapitre, et un quidam peut avoir plus d'audience qu'une personne légitime.

> En effet, si Internet et les réseaux sociaux autorisent l’accès à un volume jamais atteint de connaissances et d’infor­mation fiables, ils ont également ouvert la voie au partage d’une grande quantité de fausses informations, dont les conséquences restent rarement confinées aux réseaux sociaux.

**keypoint** = revers de la médaille-Internet = beaucoup de fausses informations sont accessibles et partagées ; elles ont des conséquences non-numériques (e.g. assaut du Capitole)

> En France comme ailleurs, et bien avant l’apparition d’Internet, les récits conspirationnistes ont embrasé les esprits tout au long de notre histoire contemporaine

**keypoint** = le conspirationniste n'est PAS récent.

> Il est donc important de le rappeler : les théories du complot prospèrent aussi sous l’effet de conditions sociales (dé)favorables.. En effet, les études témoignent d’un niveau de complotisme en moyenne plus élevé dans les pays au sein desquels les gens se sentent socialement menacés (taux de chômage élevé, par exemple) et où les institutions et les autorités sont perçues comme indignes de confiance. Si l’on ajoute à cela que certains gouvernements ne sont pas toujours innocents de tentatives de manipulations de l’opinion publique par la diffusion de fausses informations, on comprend que de nombreux facteurs sont réunis pour assurer un certain succès aux théories conspirationnistes.

**keypoint** = parmi les facteurs qui favorisent le complotisme, il y a les conditions sociales défavorables, les sociééés où les gens sont socialement menacés, et où les institutions/autorités ne sont pas dignes de confiance (parfois à raison).

> Ainsi, il a été montré que l’exposition à des thèses conspirationnistes décourage la participation à la vie démocratique par le vote, alimente les préjugés, voire la violence envers certaines catégories de la population et peut conduire au rejet du consensus scientifique sur diverses questions, telles que le dérèglement climatique ou l’efficacité des vaccins

**keypoint** = l'exposition à des thèses conspirationnistes :

- décourage la vie démocratique
- alimente les préjugés
- alimente la violence envers certaines catégories de population
- peut conduire à rejeter le consensus scientifique

> Le succès de ces récits est donc profondément enchâssé dans certaines réalités sociales lar­gement indépendantes du monde numérique. Cependant, et au-delà des seules croyances complotistes, certaines propriétés d’Internet accroissent le potentiel de nuisance des fausses informations. L’instantanéité et l’ubiquité des réseaux sociaux, notamment, permettent à des contenus nuisibles d’apparaître et de se diffuser simultanément aux événements sur lesquels elles portent.

**keypoint** = le conspirationnisme n'est donc pas dû à Internet, mais il est amplifié par lui : les fausses informations apparaissent très vite et sont partout.

> Enfin, les outils numériques décuplent les forces d’acteurs, notamment étatiques, qui cherchent à s’ingérer dans un processus électoral, manipuler l’opinion publique, tromper l’adversaire, dis­créditer les dissidents politiques, escroquer des victimes ou harceler des personnes vulnérables

**keypoint** = Internet est un outil de désinformation volontaire par des personnes malveillantes (états ou escrocs).

### Endiguer la propagation de la désinformation

> tout projet d’intervention volontaire sur ce marché de l’information, plus encore s’il est d’origine politique, pose la question de la préservation des libertés, notamment celle d’opinion, qui est au cœur de la Déclaration des droits de l’homme et du citoyen.

**keypoint** = lutter contre la désinformation est sensible, car il ne faut pas pour autant limiter la liberté d'expression.

> Pour autant, la situation actuelle de cacophonie informationnelle ne garantit nullement la pleine expression de cette liberté. En effet, l’information sur Internet est en réali-té pré-éditorialisée selon des logiques algorithmiques qui paraissent parfois échapper à leurs créateurs mêmes9 et nous asservissent alors qu’elles devaient nous servir. Ainsi, sur YouTube par exemple, 120 000 ans de temps de vidéos sont visionnés chaque jour.Parmi elles, 70% sont regardées en raison de la recommandation de l’intelligence artificielle de la plateforme

**keypoint** = c'est pas parce qu'on autorise toute expression sur Internet que la liberté d'expression est là, 70% des 120k années de vidéos youtube quotidiennes sont recommandées par IA.

> une étude de 2019 a montré que les recherches du terme «climat» sur YouTube ont majoritairement (54%) orienté les internautes vers des vidéos climatosceptiques11 .Si les réseaux sociaux deviennent un mode de plus en plus important d’information sur l’actualité, notamment pour les jeunes générations12 , toutes les enquêtes montrent qu’ils sont perçus en même temps comme le moyen le moins fiable de consulter l’actualité13

**keypoint** = réseaux sociaux sont des sources peu fiables d'information, pourtant, ce sont des sources de plus en plus utilisées, notamment par les jeunes.


> Les réseaux sociaux ne favorisent pas non plus un débat démocratique serein. Une analyse portant sur Twitter montre par exemple qu’un message a 17% de chances de plus d’être re-partagé pour chaque mot d’indignation qu’il contient14

**keypoint** = par leur nature à rechercher le buzz et le clic, les réseaux sociaux encouragent la conflictualisation des discussions.

> Ceci contribue à faire des plateformes sociales des lieux d’expression conﬂictuels, plutôt que des espaces de partage et de discussion raisonnée des points de vue. On sait d’ailleurs que les prescriptions algorithmiques des réseaux sociaux peuvent participer à la radicalisation des esprits. Selon un rapport interne de Facebook, par exemple, les individus ayant intégré un groupe extrémiste sur le réseau social l’ont fait dans deux tiers des cas suite à une recommandation de l’algorithme16

**keypoint** = les deux tiers des individus ayant intégré un groupe extrémiste sur Facebook l’ont fait suite à une recommandation de l’algorithme !

### Renforcer la résilience de la société

> On sait qu’en matière de désinformation et de théories du complot, la prévention est plus efficace que la correction17. Une étude a d’ailleurs montré que la première impression induite par une fausse information perdure souvent, même lorsque l’individu qui y a été confronté apprend qu’elle est bel et bien fausse

**keypoint** = la première impression perdure, même si on SAIT qu'elle est fausse. Du coup, il est difficile de corriger le tir si on a versé dans la théorie du complot, il vaut mieux au contraire avoir _dès la première impression_ la compréhension de la fausseté de l'information.

> On le comprend, l’instantanéité des réseaux sociaux confère dès lors un certain avantage concurrentiel aux fausses informations, rapides à générer et à diffuser, face aux informations fiables qui nécessitent, elles, du temps pour être vérifiées et recoupées.

**keypoint** = comme les fausses informations sortent plus vite que les vraies, elles ont plus de chances d'être celles qui produisent la première impresion.

> Les psychologues ont montré de longue date que, dans de nombreuses situations, nous avons ten­dance à favoriser les informations nouvelles qui vont dans le sens de nos croyances établies par rapport à celles qui pourraient les contredire (surtout lorsque les croyances en question sont en lien avec nos valeurs). Il s’agit là du célèbre «biais de confirmation», aussi appelé «conge-niality bias» par les chercheurs19

**keypoint** = biais de confirmation = on favorise les informations qui vont dans notre sens ; l'effet est d'autant plus fort que les infos sont en rapport avec nos valeurs.

> Internet facilite l’expression de ce biais, (...) nous pouvons aisément y trouver quantité d’élé­ments venant soutenir nos croyances, y compris quand ces dernières sont contraires à l’état de la connaissance sur un sujet donné

**keypoint** = Internet facilite l'expression du biais de confirmation, car comme on trouve toutes les informations, ça devient facile de trouver celles qui vont dans notre sens.


> qu’il peut même inciter certains individus concernés à s’entourer sur les réseaux sociaux de personnes qui partagent leurs croyances complotistes, formant ainsi des «chambres d’écho» au sein desquelles les positions se radicalisent progressivement20

**keypoint** = le biais de confirmation a tendance à enfermer les personnes dans des chambres d'écho.


> L’état de saturation du marché de l’information en ligne met à rude épreuve notre capacité de vigilance épistémique. En effet, le nombre de contenus auxquels nous sommes confrontés est tel que nous ne pouvons accorder que peu de temps à l’évaluation de la crédibilité de chacun d’entre eux, ce qui nous rend davantage perméables aux fausses informations21 . La répétition en ligne d’une information erronée peut de plus renforcer son pouvoir de persuasion, puisque plus nous rencontrons le même argument, le même post ou le même tweet, plus nous avons l’impression qu’il est vrai22

**keypoint** = commme Internet nous fait recevoir BEAUCOUP de contenus, il est difficile d'être vigilant et critique sur TOUS ces contenus, avec constance, du coup on est perméables aux fausses informations.

**keypoint** = plus on reçoit une information plusieurs fois (même fausse), plus on a l'impression qu'elle est vraie.

> Par conséquent, il existe un risque que les individus évoluent dans des réalités parallèles où le consensus sur des faits documentés de manière empirique par des professionnels de l’in-formation ou des théories étayées par les expériences et la littérature scientifique ne soit plus possible.

**keypoint** = on peut se forger une réalité parallèle, où l'origine du savoir n'est pas les professionnels de l'information, ou le consensus scientifique.

### La nécessité d’un espace épistémique commun

> Si la France n’est certes pas les États-Unis, une récente étude de l’université de Stanford23 fait néan­moins apparaître qu’au sein de notre pays le niveau de «polarisation affective» – à savoir, le niveau des sentiments hostiles des citoyens à l’égard d’autres partis que le leur – augmente régulièrement depuis quarante ans

**keypoint** = on n'en est pas encore au niveaux des USA, mais la "polarisation affective" (= le niveau des sentiments hostiles des citoyens à l’égard d’autres partis que le leur) est en constante augmentation depuis 40 ans.

> L’existence d’un espace épistémique commun est au fondement de la vie sociale, en particulier de la vie démocratique. Sans un tel espace, aucun problème collectif ne peut trouver de solu­tions acceptables malgré les divergences d’opinion

**keypoint** = il est essentiel qu'on soit tous d'accord sur "d'où on tire sa connaissance" afin de résoudre des problèmes collectifs même si on n'est pas d'accord.


### Objectifs et méthodes de travail de la commission

> Cette commission s’est donné pour tâche de faire un état de lieux de la recherche et des connaissances accumulées sur le sujet, tant par la consultation de la littérature scientifique et des rapports existants que par l’audition et la consultation écrite de chercheurs et d’acteurs publics et privés en lien avec le monde numérique. Elle a dû le faire en un temps très contraint (100 jours) et a, dans ces conditions, abandonné immédiatement l’objectif d’exhaustivité.

La commission vise à faire l'état des lieux des connaissances cientiques sur la désinformation, mais n'a pas pu le faire de façon exhaustive, vu le peu de temps.

> Pour traiter le sujet des perturbations de la vie démocratique par l’univers numérique, les membres de notre commission ont considéré qu’il pouvait être analytiquement découpé en sept sous-thèmes, qui organisent le plan de ce rapport.

Organisation du rapport :

- mécanismes psychosociaux susceptibles de nous rendre perméables aux fausses informations
- possibilités d’altération des logiques algorithmiques du marché en ligne de l’information
- logiques économiques de la diffusion des fausses informations et de la haine en ligne
- existence d’ingérences numériques d’acteurs étrangers, étatiques ou privés
- question de la régulation de ce marché par le droit
- établir l’état de la connaissance en matière d’EMI (Éducation aux médias et à l’information) et de pédagogie de l’esprit critique
- conclusion à ce rapport = question d’une nouvelle forme de citoyenneté numérique

> Si certaines idées acquièrent dans le monde numérique une visibilité qui n’est pas proportionnée à leur représentativité, c’est parce qu’elles sont portées (c’est notamment le cas avec les anti-vaccins) par des communautés plus motivées que les autres à faire valoir leur point de vue.

**keypoint** = les communautés de la désinformation (antivax, notamment) sont plus motivés, donc font plus entendre leur voix que les autres.

## CHAPITRE 1 = Les mécanismes psychosociaux de la désinformation

> Une grande part de ce que nous savons, ou pensons savoir, ne nous vient pas de nos propres sens et expériences, mais du témoignage d’autrui. [...] L’être humain se trouve ainsi dans un état de profonde dépendance épistémique à l’égard de ses semblables.

**keypoint** = je ne peux pas construire ma propre connaissance de façon indépendante : j'ai un besoin impératif d'informations provenant d'autrui.

> Si cette situation nous permet d’élargir de beaucoup notre volume de connaissances par rapport à ce que nous pourrions savoir seuls, elle nous expose aussi au risque d’être involontairement induits en erreur, voire dé­libérément trompés par les autres.


**keypoint** = ma dépendance épistémologique à autrui me rend vulnérable à une erreur de la part d'autrui (volontaire ou non).

> L’existence d’un tel risque ne nous empêche pas d’adopter une forme de confiance par défaut envers les informations rencontrées. En ef­fet, la recherche montre que nous avons en moyenne tendance à accepter, plutôt qu’à re­jeter les propositions nouvelles qui nous sont soumises24 Notre propension à prendre pour vrai ce qui nous est communiqué n’est pas en soi une attitude irrationnelle. En effet, en situation normale, la plupart des informations qui nous sont transmises par les membres de notre entourage sont vraies – il s’agit généralement d’informations banales sans grands enjeux épistémiques. D’un point de vue statistique, il est donc plutôt rationnel de se montrer a priori confiant à l’égard de ce qui nous est rapporté, et de ne rejeter que ce qui est très invraisemblable ou manifestement faux (ce que nous faisons effectivement la plupart du temps)26 . Cependant, dans un monde où quantité d’informations nous proviennent désormais d’Internet et des réseaux sociaux, une telle confiance minimale par défaut de­meure-t-elle raisonnable

**keypoint** = on a tendance à tenir pour vrai de façon optimiste les informations reçues de la part d'autrui. Cette tendance est plutôt rationelle puisqu'habituellement, autrui ne cherche pas à nous tromper. En revanche, sur internet, la donne est différente, et cet optimisme est questionnable.

### La représentation des fausses informations sur Internet

> La recherche académique est aujourd’hui incapable de fournir une estimation précise de la part de la désinformation sur les réseaux sociaux et, plus largement, sur Internet27 . En réalité, il s’agit là d’une estimation extrêmement difficile à produire, dont le résultat serait de toute façon largement ﬂuctuant dans le temps et selon les régions linguistiques ou pays considérés. On sait par exemple que les périodes électorales dans les pays démocratiques sont particulièrement propices à la diffusion en ligne de fausses informations

**keypoint** = il n'y a pas d'estimation précise de la part de la désinformation sur Internet ! Et celle-ci est probablement évolutive (e.g. augmente en période électorale).

> les infox sont pourtant minoritaires parmi l’ensemble des contenus d’actualité auxquels s’exposent les internautes américains, y compris en période électorale. C’est ce que montrent les études qui se sont penchées sur les sources d’information consultées par les Américains: les sites Internet connus pour publier de fausses informations ne composent qu’une faible part de leur régime informationnel en ligne29 . Pour ce qui est de la France, les données sur la consommation médiatique effective des internautes sont rares. Une récente étude30 de la Fondation Descartes montre cependant que, dans l’ensemble, les Français s’informent eux aussi majoritairement sur des sources web fiables [...] Dès lors, si l’on peut affirmer que les sites web publiant des infox sont dans l’ensemble beaucoup moins consultés par les Français que les sites des médias traditionnels, les données manquent pour estimer le niveau d’exposition moyen de nos concitoyens aux fausses informations sur les réseaux sociaux.

**keypoint** = la proportion de désinformation à laquelle on est soumis reste minoritaire devant les informations légitimes... ... mais les données manquent pour le cas spécifique de la France.

> On sait toutefois qu’en France, des infox bénéficient régulièrement d’une certaine viralité sur les réseaux sociaux32 et que leurs usagers sont plus susceptibles que les autres de se rendre sur des sites d’information non fiables33 . Ce fait, qui s’observe également aux États-Unis34 , permet de conclure que les réseaux sociaux constituent une porte d’entrée importante vers la désinfor­mation35 , quand bien même elle est probablement minoritaire dans l’ensemble des contenus d’actualités qui y circulent36 .

**keypoint** = même à taux d'exposition minoritaire, la désinformation sur les réseaux sociaux fait des dégâts, et ouvre la porte à d'autres sources de désinformation (en dehors des réseaux sociaux).

### Effets de la désinformation

> Une désinformation massive n’est pas nécessaire pour inﬂuencer négativement les personnes qui y sont exposées: un petit nombre de fausses informations peut déjà avoir des effets mesu-rables sur les croyances ou les attitudes des individus. (...) Ces résultats montrent clairement que l’exposition à un petit nombre de posts de réseaux sociaux trompeurs est suf-fisante pour produire un effet négatif (au moins à court terme) sur la disposition des individus à l’égard de la vaccination.

**keypoint** = même à taux d'exposition minoritaire, les fausses informations ont des effets mesurables négatifs sur les croyances et attitudes des individus.

> Plus généralement, l’exposition à des théories du complot en tout genre favorise la défiance à l’égard des autorités et des institutions44 , décourage la participation à la vie démocratique par le vote45 et alimente les préjugés négatifs46 , voire les attitudes hostiles47 à l’égard de diverses ca-tégories de la population. Plus inquiétant encore, certaines thèses complotistes sont fortement soupçonnées de participer à la radicalisation des esprits au sein de groupes extrémistes (isla-mistes ou d’extrême droite, par exemple) et de faciliter ainsi le passage de ces groupes à des actions violentes ou terroristes48 . Plusieurs études récentes ont par ailleurs observé l’existence d’un lien statistique significatif entre le fait d’adhérer à des théories du complot sur la covid-19 et le fait de manifester l’intention de commettre des actes violents49

**keypoint** = l'exposition à des thèses conspirationnistes :

- décourage la vie démocratique
- alimente les préjugés
- alimente la violence envers certaines catégories de population
- peut conduire à rejeter le consensus scientifique
- participent à la radicalisation extrémiste
- facilite les actions violentes

### Distinguer le vrai du faux sur Internet

> La désinformation possède souvent un caractère politique, dans le sens où elle vise à jeter le discrédit sur les membres des partis adverses ou sur leurs positions ou, inversement, à valori­ser le camp duquel elle provient

**keypoint** = il peut y avoir une motivation politique derrière une désinformation volontaire ; dit autrement, la désinformation est un outil (voire une arme) politique.

> Si les individus ont effectivement tendance à croire davantage aux informations allant dans le sens de leur positionnement politique, des études montrent que, pour autant, «la politique ne l’emporte pas sur la vérité51». En effet, des informations vraies mais politiquement discordantes sont en moyenne davantage crues que des infox politiquement concordantes52 . À eux seuls, les biais partisans ne suffisent donc pas à donner du crédit à certaines désinformations politiques rencontrées sur Internet ou les réseaux sociaux.

**keypoint** = les biais partisans et biais de confirmation ne l'emportent pas forcément sur la vérité et le sens critique, en matière de politique.

> La raison pour laquelle il arrive aux individus de se fier à de fausses informations relève proba­blement moins d’une motivation à y croire que de la simple incapacité à les identifier comme fausses. (...) . Il n’est dès lors pas surprenant que nous soyons plus à risque de prendre pour vraie une infox lorsque nous manquons de connaissances ou avons des connaissances erronées sur le sujet en question54 .

**keypoint** = c'est au conditionnel, mais le fait de "tomber" dans la désinformation procède alors plus du manque d'armes critiques, ou d'autodéfense critique, plutôt que de la motivation partisane ou le biais de confirmation. Du coup, moins on a de connaissance sur un sujet, plus on a de risque de céder à la désinformation.

> Cependant, la connaissance n’immunise pas systématiquement contre le risque d’accorder du crédit à de fausses informations56 . Ces dernières peuvent pénétrer l’esprit des individus en profitant de leur manque de vigilance, de leur distraction, voire d’une certaine forme de paresse intellectuelle. En effet, soupeser et analyser une information nouvelle avant de l’intégrer ou de la rejeter demande un effort cognitif plus important que de se fier à la première impression qu’elle nous laisse57 . Or, nous nous comportons généralement en «avares cognitifs», préférant minimiser nos efforts mentaux58 .

**keypoint** = la connaissance n’immunise pas systématiquement contre le risque d’accorder du crédit à de fausses informations : il faut impérativement exercer sa vigilance critique... Du coup, la moindre faiblesse, distraction, paresse intellectuelle, ... peut suffire à céder à la désinformation.

> Il existe néanmoins des différences interindividuelles dans la propension à se contenter ou non de suivre sa seule intuition face à une information ou donnée nouvelle. La recherche sur la manière dont l’être humain raisonne montre que nous sommes tous équipés de deux systèmes de traitement de l’information: le premier, rapide et intuitif; le second, plus lent et réﬂexif, sus­ceptible de nous faire revenir sur une évaluation du premier59 . Cependant, certaines personnes qualifiées de «réﬂexives» ou «d’analytiques» sont davantage enclines que d’autres, dites «in­tuitives», à faire appel à leur second système de traitement de l’information et, partant, à ré­viser si besoin une première impression erronée. Ces différences de style de pensée entre les individus peuvent être mesurées au moyen de divers tests cognitifs60

**keypoint** = on a tous deux modes de pensées, intuitif et analytique ; les personnes qui favorisent naturellement le mode analytique sont mieux armées contre la désinformation.

> Une étude expérimentale62 a par ailleurs établi que si l’on entrave la vigilance des individus face à des informations nouvelles, les poussant donc à se fier à leur seule intuition, leur capacité à identifier les infox diminue. Il semblerait donc que la crédulité résulte dans bien des cas d’un défaut de vigilance cognitive. Or, les réseaux sociaux n’incitent assurément pas à une telle vigilance, dans la mesure où les contenus d’information sérieux y sont souvent noyés parmi les contenus de divertissement

**keypoint** = c'est bien le défaut de vigiclance cognitive qui est à la base de la désinformation ; or sur les réseaux sociaux, domaine du divertissement, on n'est par défaut PAS vigilants.

> Il arrive en effet aux individus de décider de partager sur les réseaux sociaux des informations qu’ils ne considèrent pourtant pas comme vraies quand on leur demande de les évaluer64 . Or, ce comportement relèverait moins d’une volonté de tromper les autres que de la distraction et de la recherche de «likes».

**keypoint** = la recherche du "like" va parfois jusqu'à faire partager des informations qu'on sait fausses !

> L’un d’entre eux est l’effet de répétition d’un message. De nombreuses études montrent que plus une information – qu’elle soit vraie ou fausse – est répétée à un individu, plus ce dernier aura tendance à la croire vraie67 . Une seule exposition préalable à un contenu peut déjà suffire à augmenter sa crédibilité lorsqu’il est vu une seconde fois.

**keypoint** = plus une information est répétée, plus on va la croire vraie... indépendamment de sa véracité ou non ! L'effet est actif dès la première répétition.

> Ce phénomène est renforcé par le fait que si l’on se souvient généralement du message en question, on tend à en oublier la source68 . Ainsi, une fausse information qui nous avait initia­lement paru douteuse en raison de sa source peu fiable pourra nous apparaître comme vraie lorsque nous la croiserons à nouveau dans un autre contexte

**keypoint** = l'effet de répétition est empiré par le fait qu'on se souvient mieux de l'information que de sa source. Du coup, si on a reçu une infox une première fois, qu'on l'a identifiée comme fausse (notamment grâce à sa source), si on la reçoit une deuxième fois, on ne va pas forcément se souvenir que la première source était pipeau, on va se contenter de se souvenir de la répétition, et donc lui accorder du poids... alors même qu'on la savait pipeau la première fois !

> De manière plus pernicieuse, les opérations de fact checking, en donnant de la visibili-té aux infox auxquelles elles s’attaquent, pourraient bien elles aussi contribuer à les crédibiliser par effet de répétition69 .

**keypoint** : WTF, cet effet "répétition == véracité" s'appliquerait même si la première répétition était une vidéo dénonçant l'info comme fausse !

> Enfin, la défiance à l’égard des médias, des institutions et du gouvernement est un facteur corrélé tant avec la fréquentation sur Internet de sources d’information non fiables70 qu’avec l’adhésion aux théories du complot71 . Cela s’explique probablement par le fait qu’une telle défiance conduit les personnes concernées à rechercher des informations sur des sources «al­ternatives» aux médias traditionnels, qu’elles considèrent comme biaisés, corrompus ou à la solde du pouvoir. Ces sources d’information font la part belle aux théories du complot

**keypoint** : il y a corrélation entre la défiance envers les médias/institutions/gouvernement et la désinformation/théories du complot ; notamment parce que les personnes en défiance cherchent des sources d'informations alternatives pour éviter les sources officielles qui seraient corrompues.

> On sait par ailleurs que les personnes affectées par un sentiment ou une crainte de préca­risation, de stigmatisation ou de déclassement sont particulièrement à risque de céder aux théories du complot72 . Si elles le sont, c’est certainement parce que les théories du complot leur offrent une grille de lecture du monde susceptible de conférer un sens à leur situation et de désigner une cause univoque aux injustices et menaces sociales dont elles se considèrent victimes73

**keypoint** : les personnes précaires (ou craignant de l'être) sont plus sensibles aux théories du complot ; en effet, ces théories du complot "simplifient" leur vision du monde, et donnent du sens à l'injustice qu'elles perçoivent.

### Conclusion du chapitre 1

> Au regard de ce que nous apprend la recherche, la vigilance cognitive et le développement de notre esprit analytique constituent probablement les meilleurs remparts individuels face à aux fausses informations. Dès lors, la piste d’action qui semble la plus prometteuse pour lutter contre les effets délétères de la désinformation est celle du renforcement de la formation à l’esprit critique et de l’éducation aux médias et à l’information (EMI) (R. 27 et 29). La forma­tion à l’esprit critique doit impérativement se faire sur la base de contenus pédagogiques dont l’efficacité aura été scientifiquement évaluée

**keypoint** = vigilance cognitive + esprit analytique = meilleurs remparts individuels face aux fausses informations (du coup, l'éducation de la population dans ces domaines est une bonne piste pour lutter contre la désinformation).

> Par ailleurs, la recherche scientifique sur la prévalence de la désinformation en ligne, sur ses effets ainsi que sur les mécanismes par lesquels elle affecte les individus doit être soutenue et renforcée dans notre pays (R. 1). En effet, les données étudiées dans la littérature scientifique portent trop rarement sur la France, et les conclusions de travaux basés sur des données issues d’autres pays – États-Unis, principalement – ne sont pas nécessairement transposables chez nous

**keypoint** = il faut intensifier la recherche scientifique sur la désinformation en ligne (proportion, effets, mécanismes), car les études actuelles ne portent pas sur la France.

> La France, via l’Union européenne, devrait en outre exiger des plateformes numériques qu’elles ouvrent plus largement l’accès à leurs données aux chercheurs afin qu’ils puissent étudier les phénomènes de désinformation en ligne sous leurs différents aspects

**keypoint** = l'UE devrait essayer de faire pression sur les GAFAM pour obtenir les données permettant de mener des recherches scientifiques sur la désinformation.

> Pour finir, il importe de souligner que la lutte contre la désinformation dans notre pays ne pour­ra passer uniquement par des mesures visant à inciter les individus à la vigilance sur Internet ou à améliorer le fonctionnement algorithmique des réseaux sociaux. C’est plus profondément le lien de confiance entre les citoyens et les médias et les institutions qu’il s’agit de retisser

**keypoint** = pour lutter contre la désinformation, il faudra également travailler sur la confiance qu'ont les citoyens envers les institutions.

## CHAPITRE 2 = Logiques algorithmiques

REPRENDRE LE TRAVAIL ICI

CHAPITRE 2 = Logiques algorithmiques

TITRE = De la nécessité de la nuance

La connaissance scientiﬁque sur la manière dont les algorithmes façonnent nos croyances ou nos comportements, notamment politiques, n’est pas encore stabilisée et fait parfois valoir des données et des arguments qui peuvent paraître contradictoires.
...
Ceux qui consomment des informations venant de la presse par ce truchement ne lisent le plus souvent qu’un article80 , et sont moins susceptibles de lire l’intégralité du journal que ceux qui y ont accès dans d’autres conditions. De ce fait, ce seront souvent les thématiques plutôt que les supports qui domineront l’éditorialisation numérique
...
on constate que le marché cognitif y est animé par des eﬀets de concentration d’attention brefs, soudains et massif81 . Cette concen­tration temporelle de l’attention constitue ce que certains appellent le buzz. Cela prend une forme très tangible lorsqu’on observe à grande échelle la façon dont notre attention collective est orientée vers une histoire qui fera l’actualité un bref instant pour nous conduire à une autre, qui n’aura pas plus d’espérance de vie.
...
Autrement dit, l’augmentation importante du nombre des sources et du volume des ﬂux d’information engendrée par le développement d’Internet n’a pas inversé la tendance à l’homogénéisation des thématiques d’actualité captant massivement l’attention du public.
...
On entend souvent qu’Internet et les réseaux sociaux sont envahis par les fausses informations, idée qu’il faut fortement nuancer, comme nous l’avons vu dans le chapitre précédent: plusieurs études, conduites tant aux États-Unis qu’en France, soulignent que la désinformation constitue probablement une part minoritaire du volume globale des actualités consultées sur les réseaux sociaux, et plus largement sur Internet83 . Pour autant, il faut se garder d’en conclure que la dé-sinformation en ligne ne constituerait dès lors pas un problème. En eﬀet, la question du seuil à partir duquel des eﬀets tangibles de la désinformation peuvent être observés est laissée en suspens par les études qui se focalisent sur la part de la population exposée à ces informations
...
une étude85 montre que les médias traditionnels ont tendance à reprendre certaines informations de ces sources douteuses lorsqu’elles vont dans le sens de leur inclination parti-sane, participant ainsi à leur mise en avant.
...
De même que la désinformation en ligne ne doit pas être surestimée, gardons-nous d’exagérer son inﬂuence sur les grands événements sociaux86 . La polarisation politique par exemple ne peut que partiellement s’expliquer par le contexte numérique, et on ne trouve pas dans la lit-térature scientiﬁque de réponse ferme à la question du rôle qu’y jouent les réseaux sociaux et Internet87 . L’impact de la désinformation sur les résultats électoraux mériterait d’ailleurs aussi d’être scientiﬁquement mieux établi88
Le plus probable est que de tels phénomènes soient plurifactoriels et que leur explication ne puisse donc reposer sur la seule inﬂuence du monde numérique et des perturbations qu’il provoque.
il faut souligner que nous ne sommes pas incompétents quand il s’agit de détecter les fausses informations et que, dans l’ensemble, nous les trouvons

TITRE = Les bouleversements algorithmiques

La prudence s’impose donc lorsque l’on aborde le lien entre les algorithmes et la conﬁguration des plateformes avec les phénomènes sociaux négatifs qu’ils sont accusés de produire. Pour autant, les réseaux numériques ont des spéciﬁcités90 qui contribuent de manière inédite à l’am­pliﬁcation de ces nuisances. D’abord, la taille des réseaux numériques, le nombre de contacts que nous pouvons y avoir ou encore la visibilité potentielle des messages que nous y faisons circuler sont plus importants que jamais. Ensuite, dans les interactions hors ligne, la proximité spatiale entre les individus les incite généralement à éviter l’insulte ou l’invective; les réseaux sociaux n’oﬀrent pas cette caractéristique paciﬁcatrice. Les échanges sur Internet incitent sou­vent à l’intolérance91 et à ce que l’on appelle la désinhibition numérique92 . Enﬁn, la multiplicité des sources d’informations a tendance à favoriser une balkanisation des perceptions de la réalité, comme nous l’avons évoqué dans l’introduction de ce rapport.
...
Todo = résumer ces trois points ci-dessous :
Les principaux eﬀets de la révolution algorithmique en matière d’organisation de l’information peuvent être subdivisés en trois axes, que nous allons explorer successivement dans le reste de ce chapitre:

l’éditorialisation algorithmique: la manière dont les algorithmes régissent à la fois l’ordre et la fréquence d’apparition des informations, selon une logique de captation de l’attention;
le calibrage social: la façon dont les réseaux sociaux altèrent la perception de la représentativité et de la popularité de certains points de vue;
l’inﬂuence asymétrique: le fait qu’Internet permette à des individus motivés d’accéder à une visibilité numérique qui excède de beaucoup leur représenta-tivité, rendant ainsi possible la prévalence de certains discours extrêmes qui proﬁtent des conditions numériques pour sortir de leur espace de radicalité et diﬀuser leurs argumentaires.

...
L’un des rôles des médias est d’éditorialiser les informations d’actualité, c’est-à-dire de les sé-lectionner et de les hiérarchiser pour son public. (...) Pour un journal papier traditionnel, par exemple, c’est la salle de rédaction et son rédacteur en chef qui choisissent et organisent l’information jugée pertinente
...
Chacun com-prend qu’un article en première page, occupant plus de colonnes ou assorti de photos, gagnera davantage de visibilité. De la même façon, les plateformes éditorialisent l’information. Elles le font cependant selon une logique algorithmique qui reste opaque pour les utilisateurs93 . Lorsqu’une recherche est faite sur Google ou YouTube, ou encore qu’un ﬁl Facebook est ouvert, certaines informations sont présentées préférentiellement et ont de ce fait plus de chances d’être prises en compte par l’internaute.
...
Le discret travail d’éditorialisation de l’information des algorithmes pourrait même, dans certaines circonstances, inﬂuer sur les préférences électorales de leurs utilisateurs98 .
...
Ce que nous pourrions penser relever de notre liberté de choix se révèle ainsi, parfois, le pro-duit d’architectures numériques inﬂuençant nos conduites
...
Le terme inquié-tant de «dark patterns» a ainsi cristallisé ces dernières années les inquiétudes autour de la capacité du design des plateformes à se jouer des régularités de notre système cognitif, jusqu’à nous faire prendre des décisions malgré nous
...
La question des darks patterns99 (interfaces conçues dans le but de manipuler ou tromper les utilisateurs) et celle de la possibili-té de leur régulation exigent de prendre en compte la probléma­tique du design des interfaces utilisateurs. En eﬀet, même au-delà de toute intention maligne, les choix de design ont nécessaire­ment une inﬂuence sur le comportement des utilisateurs sur les plateformes numériques. 
...
Recommandation
Ouvrir une réﬂexion en vue d’une régulation sur l’importance de la question du design des interfaces utilisateurs (R2).
...
La logique qui oriente la conception de ces architectures numériques ne répond, la plupart du temps, qu’à un objectif économique: il s’agit pour les plateformes numériques de retenir aussi longtemps que possible l’attention de leurs utilisateurs, aﬁn de pouvoir la convertir en ressources ﬁnancières au moyen d’espaces publicitaires payants; ou encore de les inciter à partager plus de données, in ﬁne monétisables, qu’il n’est nécessaire au strict fonctionnement du service
...
Le problème est que cet enfermement n’est pas seulement dommageable pour les individus – ce qui serait en soi une raison suﬃsante pour s’en inquiéter – mais produit également des eﬀets collectifs négatifs. (...)l’entreprise a calibré son algorithme de manière à attribuer5 fois plus de poids à ces expressions d’indigna­tion, assurant ainsi aux contenus concernés une visibilité maximale dans les ﬁls d’actualité101 . Dans ces conditions, comment s’étonner des eﬀets de polarisation aﬀective que l’on observe?
...
l’algorithme de YouTube conduisait vers des contenus de plus en plus extrêmes, pavant ainsi la voie à la radicalisation105 . Cet algo-rithme a été jugé responsable d’une partie de la progression des extrêmes-droites allemandes et états-uniennes106 .
...

TITRE = Perturbation du calibrage social

De ce fait, notre opinion naissante sur une question donnée peut largement être inﬂuencée par la visibilité de celle que les autres ont exprimée à son sujet, en particulier s’ils font partie de notre réseau d’amis ou nous paraissent socialement semblables. La numé-risation des relations sociales et la multiplication des producteurs de contenus d’information perturbent beaucoup notre calibrage social108 , c’est-à-dire l’accès raisonné que nous avons à l’avis des autres
...
D’une part, elle conduit à accorder une prime aux contenus que la métrique numérique a rendus populaires. Ainsi, les algorithmes qui organisent la visibilité de l’information ont pour but de maximiser l’attention des utilisateurs et leur engagement plutôt que de proposer des sources ﬁables109 et équilibrées110
...
Cette disposition pourrait paraître raisonnable en partant du principe qu’une intelligence collective a plus de chances de faire émerger les points de vue solides et argumentés. Il n’en est rien, en raison de l’existence de ce que l’on nomme le biais de popularité1(...) À un certain niveau de popularité, la diﬀu­sion d’un article, par exemple, ne cessera de s’ampliﬁer.
...
Recommandation
Permettre aux utilisateurs de mieux se représenter l’état du réseau et la préva­lence réelle des opinions en désactivant par défaut les métriques de popularité et l’éditorialisation algorithmique, et en mettant en avant des métriques permettant de juger de la qualité épistémique des contenus (historique de partage notam­ment) (R3).
...
D’autre part, nous avons tendance à nous associer sur les réseaux sociaux (comme dans la vie réelle) à des personnes qui nous ressemblent et partagent nos points de vue, et à nous éloigner de celles qui nous paraissent au contraire trop dissemblables
...
Ainsi peuvent se former des communautés épistémiques au sein desquelles émergent des consensus illusoires et où s’opère un renforcement mutuel des opinions114 .
...

TITRE = Inﬂuences asymétriques et radicalisation

Très tôt, plusieurs études115 ont montré que, sur Internet, un petit nombre de personnes mo-tivées pouvait inﬂuencer l’opinion. Internet a en eﬀet permis l’émergence de ce que certains nomment, en référence aux thèses de l’école de Columbia, des «super leaders d’opinion116»
...
en réalité, dans la cité numérique, certains ont beaucoup plus voix au chapitre que les autres
...
Cela ne serait pas nécessaire-ment problématique s’il n’était démontré que cette conﬁguration favorisant les inﬂuenceurs numériques les plus visibles constitue un facteur essentiel de la propagation virale des fausses informations119 . Ceux-ci ne sont pas nécessairement producteurs ou relais de fausses informa­tions, mais lorsqu’ils cèdent à la tentation d’en partager, ils deviennent les causes principales de cascades de désinformation120 .
...
Recommandation
Encourager les plateformes à une modération plus attentive des inﬂuenceurs aﬁn de les responsabiliser.
...
D’une façon générale, la motivation des acteurs sur ce marché cognitif peut leur conférer une visibilité qui dépassera leur représentativité.
...
Il se trouve que, pour le meilleur et pour le pire, certains groupes motivés ont montré qu’ils étaient capables de préempter une part déséqui-librée de la visibilité numérique. Ainsi, sur Facebook, les mouvements anti-vaccins ont réussi – avant la pandémie – à occuper une place dominante face aux pro-vaccins121 .
...
Certaines analyses proposent de généraliser ces observations en montrant que la tendance des réseaux sociaux est d’invisibiliser les modérés au proﬁt des opinions extrêmes 122 .
...
Recommandations
Donner plus d’inﬂuence à la compétence en mettant en avant les comptes d’ex­perts et en ampliﬁant leur contenu (lorsqu’ils portent sur un sujet relatif à leur expertise) (R5).
Veiller à ce que, sur certains sujets fermement établis, le classement algorith­mique n’induise pas en erreur le public sur l’état réel des connaissances. Pour cela, encourager un dialogue entre les plateformes et les institutions scientiﬁques aﬁn que l’existence d’un consensus soit reﬂétée dans la visibilité accordée aux diverses opinions (R6).
...
En dehors des réseaux sociaux, le classement proposé par un moteur de recherche comme Google, par exemple, peut être inﬂuencé par l’activité plus ou moins coordonnée de certains réseaux militants.
...
C’est notamment le cas lorsqu’un fait d’actua-lité vient de se produire (par exemple, un attentat) et n’a pas encore généré beaucoup d’articles. Dès lors, si un groupe motivé par la manipulation de l’opinion agit rapidement, il peut, au moins provisoirement, détourner les premières recherches vers des interprétations idéologisées de l’événement.
...
L’action de tels groupes motivés peut contribuer à produire des bulles épistémiques126,espaces numériques à l’intérieur desquels l’esprit critique peine à faire valoir ses droits127 . Dans ces communautés virtuelles, les fausses informations peuvent se diﬀuser sans rencontrer beau­coup de contradictions. Il est documenté qu’elles alimentent l’extrémisme et la polarisation aﬀective128
...
Ces groupes peuvent par ailleurs agir de façon plus ou moins coordonnée pour signaler en essaim des comptes qui contrarient leur combat idéologique et obtenir des suspen­sions ou des bannissements.
Recommandation
Se prémunir contre le risque de sur-modération en analysant plus ﬁnement les signalements d’utilisateurs (signalements en essaim) (R7).

TITRE = Conclusion du chapitre 2

REPRENDRE ICI
